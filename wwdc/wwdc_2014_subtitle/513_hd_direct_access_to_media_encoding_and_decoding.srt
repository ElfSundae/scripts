

1
00:00:00.506 --> 00:00:09.516 A:middle
[ Silence ]

2
00:00:10.016 --> 00:00:16.000 A:middle
[ Applause ]

3
00:00:16.366 --> 00:00:17.086 A:middle
&gt;&gt; Hi everyone.

4
00:00:17.086 --> 00:00:18.016 A:middle
Thanks for coming today.

5
00:00:18.456 --> 00:00:19.586 A:middle
My name is David Eldred.

6
00:00:19.586 --> 00:00:22.056 A:middle
This is session 513
and we're going to talk

7
00:00:22.056 --> 00:00:25.156 A:middle
about Video Encoders
and Decoders today.

8
00:00:25.866 --> 00:00:26.296 A:middle
All right.

9
00:00:26.716 --> 00:00:28.916 A:middle
We want to make sure that
no matter what you're doing

10
00:00:28.916 --> 00:00:31.216 A:middle
with the video in your
application, you have access

11
00:00:31.596 --> 00:00:33.416 A:middle
to hardware encoders
and decoders.

12
00:00:34.256 --> 00:00:36.136 A:middle
This will help users.

13
00:00:36.136 --> 00:00:38.596 A:middle
This will improve user
experience in a number of ways.

14
00:00:39.426 --> 00:00:41.196 A:middle
Obviously, they'll
get better performance

15
00:00:41.196 --> 00:00:46.176 A:middle
and they will be far more
efficient, but most importantly,

16
00:00:46.176 --> 00:00:47.616 A:middle
this will extend battery life.

17
00:00:48.236 --> 00:00:53.456 A:middle
Users will really appreciate it
if their OS X, their portables

18
00:00:53.736 --> 00:00:56.616 A:middle
as well as their iOS devices
have improved battery life.

19
00:00:57.356 --> 00:01:00.486 A:middle
And as an added bonus, people
with portables will love it

20
00:01:00.486 --> 00:01:02.096 A:middle
if their fans don't kick

21
00:01:02.096 --> 00:01:03.916 A:middle
in every time they're
doing video processing.

22
00:01:05.256 --> 00:01:09.366 A:middle
So today, we're going
to break this --

23
00:01:09.366 --> 00:01:11.396 A:middle
first, we're going to break this
down into a few case studies.

24
00:01:11.396 --> 00:01:13.806 A:middle
We're going to look at
some common user scenarios.

25
00:01:14.546 --> 00:01:16.696 A:middle
The first scenario we're going
to talk about is the case

26
00:01:16.696 --> 00:01:19.706 A:middle
where you have a stream of H.264
data coming in over the network

27
00:01:20.056 --> 00:01:21.406 A:middle
and you want to display
that inside

28
00:01:21.406 --> 00:01:22.766 A:middle
of a layer in your application.

29
00:01:23.356 --> 00:01:25.556 A:middle
The next one we're going
to talk about is the case

30
00:01:25.556 --> 00:01:28.746 A:middle
where you have a stream of H.264
data coming in over the network,

31
00:01:29.016 --> 00:01:30.186 A:middle
but you don't just
want to display

32
00:01:30.186 --> 00:01:33.026 A:middle
that in your application, but
you actually want to get access

33
00:01:33.026 --> 00:01:34.736 A:middle
to those decoded
CV pixel buffers.

34
00:01:36.646 --> 00:01:39.686 A:middle
Next, we'll be talking
about when the case

35
00:01:39.686 --> 00:01:42.596 A:middle
where you have a sequence of
images coming in from the camera

36
00:01:42.596 --> 00:01:44.086 A:middle
or someplace else and you'd

37
00:01:44.086 --> 00:01:46.316 A:middle
like to compress those
directly into a movie file.

38
00:01:48.086 --> 00:01:51.826 A:middle
And accompanying that, there's
the case where you have a stream

39
00:01:51.826 --> 00:01:54.326 A:middle
of images coming in from
the camera or someplace else

40
00:01:54.906 --> 00:01:57.186 A:middle
and you'd like to compress
those but get direct access

41
00:01:57.186 --> 00:01:58.726 A:middle
to those compressed
sample buffers

42
00:01:59.066 --> 00:02:00.616 A:middle
so that you can send
them out over the network

43
00:02:00.996 --> 00:02:02.356 A:middle
or do whatever you
like with them.

44
00:02:03.336 --> 00:02:05.906 A:middle
And then finally, we're
going to give you an intro

45
00:02:05.906 --> 00:02:07.486 A:middle
to our new multi-pass APIs

46
00:02:07.486 --> 00:02:11.136 A:middle
that we're introducing
in iOS8 and Yosemite.

47
00:02:11.446 --> 00:02:15.836 A:middle
All right, let's
do a quick overview

48
00:02:15.836 --> 00:02:17.166 A:middle
of our media interface stack.

49
00:02:17.406 --> 00:02:19.976 A:middle
You've seen stuff like
this earlier this week,

50
00:02:20.026 --> 00:02:23.796 A:middle
but we'll do it once more, and
there's a little focus on video

51
00:02:23.796 --> 00:02:27.296 A:middle
in my view of this, because
we're talking about video.

52
00:02:28.116 --> 00:02:30.496 A:middle
So at the top we have AVKit.

53
00:02:30.496 --> 00:02:35.196 A:middle
AVKit provides very easy-to-use
high level view level interfaces

54
00:02:35.196 --> 00:02:36.056 A:middle
for dealing with media.

55
00:02:37.496 --> 00:02:39.316 A:middle
Below that, we have
AVFoundation.

56
00:02:39.686 --> 00:02:42.226 A:middle
AVFoundation provides an
easy-to-use objective C

57
00:02:42.226 --> 00:02:45.026 A:middle
interface for a wide
range of media tasks.

58
00:02:46.186 --> 00:02:48.726 A:middle
And below that, we
have Video Toolbox.

59
00:02:49.076 --> 00:02:51.796 A:middle
Video Toolbox has been
there on OS X for a while,

60
00:02:51.796 --> 00:02:55.006 A:middle
but now it's finally
populated with headers on iOS.

61
00:02:55.676 --> 00:02:57.996 A:middle
This provides direct
access to encoders

62
00:02:57.996 --> 00:02:58.646 A:middle
and decoders [applause].

63
00:03:01.306 --> 00:03:05.926 A:middle
And below that we have
Core Media Core Video.

64
00:03:06.246 --> 00:03:09.226 A:middle
These frameworks provide
many of the necessary types

65
00:03:09.226 --> 00:03:10.246 A:middle
that you'll see throughout
the --

66
00:03:10.346 --> 00:03:14.236 A:middle
in the interfaces in
the rest of the stack.

67
00:03:15.076 --> 00:03:18.326 A:middle
So today, we're going
to focus on AVFoundation

68
00:03:18.326 --> 00:03:19.456 A:middle
and the Video Toolbox.

69
00:03:19.896 --> 00:03:22.596 A:middle
In AVFoundation, we'll be
looking at some interfaces

70
00:03:22.596 --> 00:03:25.616 A:middle
that allow you to decode
video directly into a layer

71
00:03:25.616 --> 00:03:30.676 A:middle
in your application or compress
frames directly into a file.

72
00:03:30.676 --> 00:03:34.156 A:middle
And the Video Toolbox we'll
be looking at these interfaces

73
00:03:34.156 --> 00:03:37.216 A:middle
to give you more direct access
to encoders and decoders

74
00:03:37.756 --> 00:03:40.186 A:middle
so you can decompress
directly to CV pixel buffers

75
00:03:40.186 --> 00:03:42.836 A:middle
or compress directly
to CM sample buffers.

76
00:03:44.376 --> 00:03:48.676 A:middle
So a quick note on
using these frameworks.

77
00:03:48.676 --> 00:03:50.896 A:middle
A lot of people think they have
to dive down to the lowest level

78
00:03:50.896 --> 00:03:52.286 A:middle
and use the Video
Toolbox in order

79
00:03:52.286 --> 00:03:56.026 A:middle
to get hardware acceleration,
but that's really not true.

80
00:03:57.366 --> 00:03:59.806 A:middle
On iOS, AVKit, AVFoundation

81
00:03:59.806 --> 00:04:02.666 A:middle
and Video Toolbox will
all use hardware codec.

82
00:04:04.046 --> 00:04:07.236 A:middle
On OS X, AVKit and AVFoundation
will use hardware codec

83
00:04:07.236 --> 00:04:09.596 A:middle
when they're available on
the system and when you --

84
00:04:09.756 --> 00:04:10.876 A:middle
when it's appropriate.

85
00:04:11.706 --> 00:04:14.146 A:middle
And Video Toolbox will
use hardware codec

86
00:04:14.296 --> 00:04:17.976 A:middle
when it's available on system
and when you request it.

87
00:04:19.026 --> 00:04:19.375 A:middle
All right.

88
00:04:20.646 --> 00:04:23.056 A:middle
So before we dive into
more stuff, we're going --

89
00:04:23.206 --> 00:04:25.866 A:middle
I'm going to do a quick look
at this cast of characters.

90
00:04:25.866 --> 00:04:27.126 A:middle
These are some of
the common types

91
00:04:27.126 --> 00:04:29.486 A:middle
that you'll encounter
in these interfaces.

92
00:04:31.606 --> 00:04:33.436 A:middle
First off, there's
CVPixelBuffer.

93
00:04:33.816 --> 00:04:39.476 A:middle
CVPixelBuffer contains a block
of image data and wrapping

94
00:04:39.476 --> 00:04:42.906 A:middle
that buffer of data is the
CVPixelBuffer wrapping.

95
00:04:43.286 --> 00:04:45.656 A:middle
And the CVPixelBuffer
wrapping tells you how

96
00:04:45.656 --> 00:04:46.716 A:middle
to access that data.

97
00:04:46.816 --> 00:04:49.506 A:middle
It's got the dimensions,
the width and the height.

98
00:04:49.506 --> 00:04:52.166 A:middle
It's got the pixel format,
everything you need in order

99
00:04:52.166 --> 00:04:55.916 A:middle
to correctly interpret
the pixel data.

100
00:04:56.636 --> 00:04:58.436 A:middle
Next, we've got the
CVPixelBufferPool.

101
00:04:58.436 --> 00:05:00.306 A:middle
The CVPixelBufferPool allows you

102
00:05:00.306 --> 00:05:03.136 A:middle
to efficiently recycle
CVPixelBuffer back ends.

103
00:05:03.826 --> 00:05:07.496 A:middle
Those data buffers can be very
expensive to constantly allocate

104
00:05:07.496 --> 00:05:08.266 A:middle
and de-allocate,

105
00:05:08.356 --> 00:05:11.996 A:middle
so PixelBufferPool allows
you to recycle them.

106
00:05:12.766 --> 00:05:15.726 A:middle
The way a PixelBufferPool works
is you allocate a CVPixelBuffer

107
00:05:15.726 --> 00:05:18.946 A:middle
from the pool and the
CVPixelBuffer is a ref

108
00:05:18.946 --> 00:05:19.656 A:middle
counted object.

109
00:05:19.976 --> 00:05:22.116 A:middle
When everyone releases
that CVPixelBuffer,

110
00:05:22.436 --> 00:05:25.016 A:middle
the data back end goes back
into the pool and it's available

111
00:05:25.016 --> 00:05:30.266 A:middle
for reuse next time you allocate
a PixelBuffer from that pool.

112
00:05:31.266 --> 00:05:34.336 A:middle
Next thing is
pixelBufferAttributes.

113
00:05:34.456 --> 00:05:36.636 A:middle
This isn't actually a type
like the rest of the things

114
00:05:36.636 --> 00:05:40.576 A:middle
in this list, but it's a
common object you'll see listed

115
00:05:40.576 --> 00:05:41.446 A:middle
in our interfaces.

116
00:05:41.446 --> 00:05:42.526 A:middle
You'll see requests

117
00:05:42.526 --> 00:05:44.266 A:middle
for pixelBufferAttributes
dictionaries.

118
00:05:44.996 --> 00:05:47.336 A:middle
pixelBufferAttributes are a
CF dictionary containing a set

119
00:05:47.336 --> 00:05:50.106 A:middle
of requirements for
either a CVPixelBuffer

120
00:05:50.106 --> 00:05:51.136 A:middle
or a PixelBufferPool.

121
00:05:52.646 --> 00:05:56.096 A:middle
This includes the -- this
can include several things.

122
00:05:56.096 --> 00:05:57.206 A:middle
This can include dimensions

123
00:05:57.206 --> 00:05:58.906 A:middle
that you're requesting,
the width and height.

124
00:05:59.436 --> 00:06:02.076 A:middle
This can include a specific
pixel format or a list

125
00:06:02.076 --> 00:06:04.886 A:middle
of pixel formats that
you'd like to receive.

126
00:06:05.926 --> 00:06:09.586 A:middle
And you can include specific
compatibility flags requesting

127
00:06:09.586 --> 00:06:12.636 A:middle
compatibility with specific
display technologies

128
00:06:12.636 --> 00:06:16.336 A:middle
such as OpenGL, OpenGL
ES or Core Animation.

129
00:06:19.316 --> 00:06:19.696 A:middle
All right.

130
00:06:19.696 --> 00:06:20.996 A:middle
Next, we've got CMTime.

131
00:06:21.626 --> 00:06:24.716 A:middle
CMTime is the basic
description of time

132
00:06:24.716 --> 00:06:26.006 A:middle
that you'll see in
your interfaces.

133
00:06:26.506 --> 00:06:29.716 A:middle
This is a rational
representation of a time value.

134
00:06:29.716 --> 00:06:33.656 A:middle
It contains a 64 byte time
value that's the numerator,

135
00:06:34.216 --> 00:06:36.676 A:middle
and a 32 byte time scale,
which is the denominator.

136
00:06:37.326 --> 00:06:39.096 A:middle
We use the sort of
rational representation

137
00:06:39.096 --> 00:06:41.966 A:middle
so that these time values can
be passed throughout your media

138
00:06:41.966 --> 00:06:46.816 A:middle
pipeline and you won't have to
do any sort of rounding on them.

139
00:06:47.436 --> 00:06:47.886 A:middle
All right.

140
00:06:48.406 --> 00:06:50.446 A:middle
Next, CMVideoFormatDescription.

141
00:06:50.746 --> 00:06:52.516 A:middle
You'll see this in a
bunch of our interfaces,

142
00:06:52.576 --> 00:06:55.626 A:middle
and a CMVideoFormatDescription
is basically a description

143
00:06:55.626 --> 00:06:56.276 A:middle
of video data.

144
00:06:56.866 --> 00:06:58.346 A:middle
This contains the dimensions.

145
00:06:58.786 --> 00:07:03.446 A:middle
This includes the pixel format
and there's a set of extensions

146
00:07:03.446 --> 00:07:07.546 A:middle
that go along with the
CMVideoFormatDescription.

147
00:07:07.936 --> 00:07:11.186 A:middle
These extensions can
include information to --

148
00:07:11.866 --> 00:07:15.696 A:middle
information used for
displaying that video data just

149
00:07:15.696 --> 00:07:16.896 A:middle
as pixel aspect ratio,

150
00:07:17.356 --> 00:07:19.546 A:middle
and it can include
color space information.

151
00:07:19.866 --> 00:07:24.766 A:middle
And in the case of H.264 data,
the parameter sets are included

152
00:07:24.766 --> 00:07:26.746 A:middle
in these extensions
and we'll talk

153
00:07:26.746 --> 00:07:29.536 A:middle
about that more a
little bit later.

154
00:07:30.536 --> 00:07:32.116 A:middle
All right, next is
CMBlockBuffer.

155
00:07:32.626 --> 00:07:37.076 A:middle
CMBlockBuffer is the basic way
that we wrap arbitrary blocks

156
00:07:37.076 --> 00:07:38.096 A:middle
of data in core media.

157
00:07:39.096 --> 00:07:41.506 A:middle
In general, when you
encounter video data,

158
00:07:41.646 --> 00:07:43.586 A:middle
compressed video
data in our pipeline,

159
00:07:43.586 --> 00:07:45.346 A:middle
it will be wrapped
in a CMBlockBuffer.

160
00:07:45.916 --> 00:07:50.286 A:middle
All right, now we
have CMSampleBuffer.

161
00:07:50.596 --> 00:07:53.776 A:middle
You'll see CMSampleBuffer show
up a lot in our interfaces.

162
00:07:54.266 --> 00:07:55.726 A:middle
These wrap samples of data.

163
00:07:56.056 --> 00:07:58.356 A:middle
In the case of video,

164
00:07:58.446 --> 00:08:02.006 A:middle
CMSampleBuffer's can wrap
either compressed video frames

165
00:08:02.006 --> 00:08:05.536 A:middle
or uncompressed video frames
and CMSampleBuffer's build

166
00:08:05.536 --> 00:08:07.366 A:middle
on several of the types that
we've talked about here.

167
00:08:08.226 --> 00:08:09.796 A:middle
They contain a CMTime.

168
00:08:09.916 --> 00:08:12.056 A:middle
This is the presentation
time for the sample.

169
00:08:12.646 --> 00:08:15.706 A:middle
They contain a
CMVideoFormatDescription.

170
00:08:15.816 --> 00:08:18.446 A:middle
This describes the data
inside of the CMSampleBuffer.

171
00:08:19.826 --> 00:08:21.746 A:middle
And finally, in the case
of compressed video,

172
00:08:21.746 --> 00:08:23.236 A:middle
they contain a CMBlockBuffer

173
00:08:23.236 --> 00:08:25.586 A:middle
and the CMBlockBuffer has
the compressed video data.

174
00:08:26.446 --> 00:08:29.346 A:middle
And if it's an uncompressed
image in the CMSampleBuffer,

175
00:08:29.846 --> 00:08:32.426 A:middle
the uncompressed image
may be in a CVPixelBuffer

176
00:08:32.816 --> 00:08:34.385 A:middle
or it may be in a CMBlockBuffer.

177
00:08:34.956 --> 00:08:37.056 A:middle
All right.

178
00:08:37.056 --> 00:08:38.346 A:middle
Next, we've got CMClock.

179
00:08:39.576 --> 00:08:43.385 A:middle
CMClock is the core media
wrapper around a source of time

180
00:08:43.936 --> 00:08:46.636 A:middle
and like the clock on a
wall, there's no clocks

181
00:08:46.636 --> 00:08:48.426 A:middle
on the wall here, but
like a clock on the wall,

182
00:08:48.896 --> 00:08:52.226 A:middle
time is always moving and it's
always increasing on a CMClock.

183
00:08:53.506 --> 00:08:55.246 A:middle
One of the common clocks

184
00:08:55.246 --> 00:08:57.556 A:middle
that you'll see used
is the HostTimeClock.

185
00:08:58.026 --> 00:09:03.546 A:middle
So CMClockgetHostTimeClock will
return a clock which is based

186
00:09:03.696 --> 00:09:06.016 A:middle
on mach absolute time.

187
00:09:08.096 --> 00:09:10.516 A:middle
So CMClocks are hard to control.

188
00:09:10.516 --> 00:09:12.156 A:middle
You can't really control them.

189
00:09:12.466 --> 00:09:14.526 A:middle
As I mentioned, they're
always moving

190
00:09:14.896 --> 00:09:16.306 A:middle
and always at a constant rate.

191
00:09:16.896 --> 00:09:20.606 A:middle
So CMTimebase provides a more
controlled view onto a CMClock.

192
00:09:22.156 --> 00:09:25.606 A:middle
So if we go ahead and
create a CMClock based --

193
00:09:25.826 --> 00:09:27.956 A:middle
CMTimebase based on
the host time clock,

194
00:09:28.346 --> 00:09:31.196 A:middle
we could then set the time to
time zero on our time base.

195
00:09:32.966 --> 00:09:37.606 A:middle
Now, time zero on our time
base maps to the current time

196
00:09:37.656 --> 00:09:42.006 A:middle
on the CMClock, and you
can control the rate

197
00:09:42.096 --> 00:09:43.246 A:middle
of your time base.

198
00:09:43.346 --> 00:09:46.206 A:middle
So if you were then to go and
set your time base rate to one,

199
00:09:46.376 --> 00:09:48.866 A:middle
time will begin advancing on
your time base at the same rate

200
00:09:48.916 --> 00:09:50.596 A:middle
at which the clock is advancing.

201
00:09:51.036 --> 00:09:54.916 A:middle
And CMTimebases can be
created based on CMClocks

202
00:09:54.916 --> 00:09:57.216 A:middle
or they can be created
based on other CMTimebases.

203
00:09:58.836 --> 00:09:59.736 A:middle
All right.

204
00:10:00.576 --> 00:10:02.376 A:middle
Let's hop into our
first use case.

205
00:10:02.936 --> 00:10:05.156 A:middle
This is the case where you
have a stream of data coming

206
00:10:05.156 --> 00:10:08.746 A:middle
in over the network and
since its video data coming

207
00:10:08.746 --> 00:10:10.986 A:middle
over the network, we can
safely assume it's a cat video,

208
00:10:12.246 --> 00:10:16.916 A:middle
and so we've got
AVSampleBufferDisplayLayer,

209
00:10:16.916 --> 00:10:21.086 A:middle
which takes -- which can take
a sequence of compressed frames

210
00:10:21.476 --> 00:10:23.566 A:middle
and display it in a layer
inside of your application.

211
00:10:24.666 --> 00:10:26.846 A:middle
AVSampleBufferDisplayLayer
shipped

212
00:10:27.016 --> 00:10:29.906 A:middle
in Mavericks, and
it's new in iOS8.

213
00:10:31.026 --> 00:10:33.806 A:middle
So let's take a look inside
AVSampleBufferDisplayLayer.

214
00:10:34.846 --> 00:10:39.256 A:middle
As I mentioned, it takes a
sequence of compressed frames

215
00:10:39.256 --> 00:10:41.706 A:middle
as input and these need
to be in CMSampleBuffers.

216
00:10:42.796 --> 00:10:44.776 A:middle
Internally, it's going
to have a video decoder

217
00:10:45.656 --> 00:10:49.006 A:middle
and it will decode the
frames into CVPixelBuffers

218
00:10:49.006 --> 00:10:51.806 A:middle
and it will have a sequence
of CVPixelBuffers queued up

219
00:10:51.876 --> 00:10:53.996 A:middle
and ready to display
in your application

220
00:10:53.996 --> 00:10:54.976 A:middle
at the appropriate time.

221
00:10:55.546 --> 00:11:00.966 A:middle
But, I mentioned we were getting
our data off of the network.

222
00:11:01.186 --> 00:11:03.646 A:middle
A lot of times, when
you're getting a stream

223
00:11:03.646 --> 00:11:06.176 A:middle
of compressed video off the
network, it's going to be

224
00:11:06.176 --> 00:11:07.746 A:middle
in the form of an
elementary stream.

225
00:11:08.886 --> 00:11:10.686 A:middle
And I mentioned that CMSample --

226
00:11:10.796 --> 00:11:14.566 A:middle
AVSampleBufferDisplayLayer wants
CMSampleBuffers as its input.

227
00:11:15.836 --> 00:11:18.256 A:middle
Well, there's a little bit of
work that has to happen here

228
00:11:18.256 --> 00:11:20.036 A:middle
to convert your elementary
screen data

229
00:11:20.036 --> 00:11:21.276 A:middle
into CMSampleBuffers.

230
00:11:21.276 --> 00:11:23.766 A:middle
So let's talk about this.

231
00:11:23.766 --> 00:11:28.176 A:middle
H.264 defines a couple
of ways of packaging --

232
00:11:28.176 --> 00:11:33.226 A:middle
the H.264 spec defines a couple
of ways of packaging H.264 data.

233
00:11:33.226 --> 00:11:34.386 A:middle
The first one I'm going to refer

234
00:11:34.386 --> 00:11:35.996 A:middle
to is Elementary
Stream packaging.

235
00:11:36.506 --> 00:11:38.986 A:middle
This is used in elementary
streams, transport streams,

236
00:11:38.986 --> 00:11:41.966 A:middle
a lot of things with
streams in their name.

237
00:11:41.966 --> 00:11:43.596 A:middle
Next, is MPEG-4 packaging.

238
00:11:44.056 --> 00:11:47.596 A:middle
This is used in movie
files and MP4 files.

239
00:11:48.786 --> 00:11:52.516 A:middle
And in our interfaces that deal
with CMSampleBuffers, core media

240
00:11:52.516 --> 00:11:56.376 A:middle
and AVFoundation exclusively
want the data packaged

241
00:11:56.616 --> 00:11:58.656 A:middle
in MPEG-4 packaging.

242
00:12:00.006 --> 00:12:03.496 A:middle
So let's look closer
at an H.264 stream.

243
00:12:04.066 --> 00:12:08.336 A:middle
An H.264 stream consists
of a sequence of blocks

244
00:12:08.336 --> 00:12:10.356 A:middle
of data packaged in NAL Units.

245
00:12:10.836 --> 00:12:13.546 A:middle
These NAL Units can
contain several --

246
00:12:13.996 --> 00:12:15.566 A:middle
so this is the network
abstraction layer,

247
00:12:16.126 --> 00:12:18.416 A:middle
and these are Network
Abstraction Layer units.

248
00:12:19.266 --> 00:12:20.956 A:middle
These can contain a
few different things.

249
00:12:21.436 --> 00:12:23.446 A:middle
First off, they can
contain sample data.

250
00:12:25.846 --> 00:12:30.976 A:middle
So you could have a single
frame of video could be packaged

251
00:12:30.976 --> 00:12:36.016 A:middle
in one NAL Unit or a frame
of video could be spread

252
00:12:36.016 --> 00:12:37.386 A:middle
across several NAL Units.

253
00:12:38.286 --> 00:12:43.116 A:middle
The other thing that NAL Units
can contain is parameter sets.

254
00:12:43.446 --> 00:12:45.686 A:middle
The parameter sets, the
Sequence Parameter Set

255
00:12:45.686 --> 00:12:49.416 A:middle
and Picture Parameter
Set are chunks of data

256
00:12:49.416 --> 00:12:51.856 A:middle
of which the decoder holds
on to and these apply

257
00:12:51.856 --> 00:12:55.916 A:middle
to all subsequent frames; well,

258
00:12:55.916 --> 00:12:57.316 A:middle
until a new parameter
set arrives.

259
00:12:59.226 --> 00:13:01.536 A:middle
So let's look at
Elementary Stream packaging.

260
00:13:01.976 --> 00:13:04.786 A:middle
Elementary Stream packaging,
in Elementary Stream packaging,

261
00:13:05.126 --> 00:13:06.366 A:middle
the parameter sets are included

262
00:13:06.366 --> 00:13:08.206 A:middle
in NAL Units right
inside the stream.

263
00:13:08.396 --> 00:13:10.296 A:middle
This is great if you're
doing sequential playback.

264
00:13:10.866 --> 00:13:13.196 A:middle
You read in your parameter
sets and they apply

265
00:13:13.196 --> 00:13:16.156 A:middle
to all subsequent frames until
a new frame or sets arrive.

266
00:13:17.556 --> 00:13:21.036 A:middle
MPEG-4 packaging has the NAL
Units pulled out and it's

267
00:13:21.036 --> 00:13:24.616 A:middle
in a separate block of data,
and this block of data is stored

268
00:13:24.616 --> 00:13:26.236 A:middle
in the CMVideoFormatDescription.

269
00:13:26.786 --> 00:13:27.586 A:middle
So as I mentioned,

270
00:13:27.666 --> 00:13:32.346 A:middle
each CMSampleBuffer references
this CMVideoFormatDescription.

271
00:13:32.476 --> 00:13:35.666 A:middle
That means each frame
of data has access

272
00:13:35.756 --> 00:13:37.146 A:middle
to the parameter sets.

273
00:13:38.106 --> 00:13:40.826 A:middle
This sort of packaging
is superior

274
00:13:40.826 --> 00:13:42.246 A:middle
for random access in a file.

275
00:13:42.306 --> 00:13:44.836 A:middle
It allows you to jump anywhere

276
00:13:44.836 --> 00:13:47.106 A:middle
and begin decoding
at an I frame.

277
00:13:49.066 --> 00:13:50.356 A:middle
So what do you have to do

278
00:13:50.356 --> 00:13:52.076 A:middle
if you have an Elementary
Stream coming in?

279
00:13:52.986 --> 00:13:55.046 A:middle
Well, we've got --
you've got a couple --

280
00:13:55.276 --> 00:13:58.276 A:middle
you've got your parameter sets
and NAL Units and you're going

281
00:13:58.276 --> 00:14:01.276 A:middle
to have to package those in
a CMVideoFormatDescription.

282
00:14:02.086 --> 00:14:05.096 A:middle
Well, we provide a handy
utility that does this for you;

283
00:14:05.246 --> 00:14:07.976 A:middle
CMVideoFormatDescription
CreatefromH264ParameterSets.

284
00:14:08.516 --> 00:14:12.956 A:middle
[ Applause ]

285
00:14:13.456 --> 00:14:17.396 A:middle
All right, so the next
difference that we're going

286
00:14:17.396 --> 00:14:19.536 A:middle
to talk about between
an Elementary Stream

287
00:14:19.536 --> 00:14:23.306 A:middle
and MPEG-4 packaging
is in NAL Unit headers.

288
00:14:24.086 --> 00:14:25.286 A:middle
So each NAL Unit

289
00:14:25.286 --> 00:14:27.736 A:middle
in an Elementary
Stream will have a three

290
00:14:27.736 --> 00:14:33.166 A:middle
or four bytes start code as the
header and in MPEG-4 packaging,

291
00:14:33.256 --> 00:14:34.786 A:middle
we have a length code.

292
00:14:35.456 --> 00:14:37.616 A:middle
So for each NAL Unit in your
stream, they're going --

293
00:14:38.156 --> 00:14:41.026 A:middle
you have to strip
off that start code

294
00:14:41.026 --> 00:14:42.426 A:middle
and replace it with
a length code.

295
00:14:42.766 --> 00:14:44.066 A:middle
That's the length
of the NAL Unit.

296
00:14:45.256 --> 00:14:46.126 A:middle
It's not that hard.

297
00:14:48.096 --> 00:14:50.226 A:middle
So let's talk about
building a CMSampleBuffer

298
00:14:50.876 --> 00:14:52.626 A:middle
from your Elementary Stream.

299
00:14:52.916 --> 00:14:55.096 A:middle
First thing you're going to
have to do is take your NAL Unit

300
00:14:55.476 --> 00:15:00.496 A:middle
or NAL Units and replace the
start code with a length code.

301
00:15:02.436 --> 00:15:05.986 A:middle
And you'll wrap that NAL
Unit in a CMBlockBuffer.

302
00:15:06.646 --> 00:15:09.776 A:middle
One note here, for simplicity,
I'm showing a single NAL Unit

303
00:15:09.776 --> 00:15:12.326 A:middle
but if you have a frame that
consists of several NAL Units,

304
00:15:12.716 --> 00:15:14.506 A:middle
you need to include
all of the NAL Units

305
00:15:14.506 --> 00:15:15.746 A:middle
in your CMSampleBuffer.

306
00:15:16.876 --> 00:15:18.486 A:middle
So you have a CMBlockBuffer.

307
00:15:18.786 --> 00:15:20.306 A:middle
You have your
CMVideoFormatDescription

308
00:15:20.306 --> 00:15:21.556 A:middle
that you created
from your initial --

309
00:15:21.626 --> 00:15:25.286 A:middle
from your parameter sets,
and throw in a CMTime value,

310
00:15:25.286 --> 00:15:27.016 A:middle
that's the presentation
time of your frame,

311
00:15:27.646 --> 00:15:29.876 A:middle
and you have everything
you need in order

312
00:15:29.876 --> 00:15:33.696 A:middle
to create CMSampleBuffer
using CMSampleBufferCreate.

313
00:15:34.536 --> 00:15:38.256 A:middle
All right, let's talk

314
00:15:38.256 --> 00:15:40.336 A:middle
about AVSampleBufferDisplayLayer
in time.

315
00:15:41.086 --> 00:15:41.936 A:middle
So as we saw,

316
00:15:41.936 --> 00:15:44.826 A:middle
all CMSampleBuffers have an
associated presentation time

317
00:15:44.826 --> 00:15:48.176 A:middle
stamp, and our video
decoder's going to be spitting

318
00:15:48.176 --> 00:15:52.226 A:middle
out CVPixelBuffers each with
an associated presentation

319
00:15:52.226 --> 00:15:52.796 A:middle
time stamp.

320
00:15:53.646 --> 00:15:55.556 A:middle
Well, how does it know when
to display these frames?

321
00:15:56.516 --> 00:15:59.286 A:middle
By default, it will be driven
off of the host time clock.

322
00:16:00.466 --> 00:16:02.426 A:middle
Well, that can be a
little bit hard to manager.

323
00:16:02.426 --> 00:16:05.266 A:middle
The host time clock isn't
really under your control.

324
00:16:06.126 --> 00:16:08.796 A:middle
So we allow you to
replace the host time clock

325
00:16:08.796 --> 00:16:10.936 A:middle
with your own time base.

326
00:16:11.816 --> 00:16:14.826 A:middle
To do this you set the time --
you know in the example here,

327
00:16:15.026 --> 00:16:18.566 A:middle
we're creating a time base
based on the host time clock

328
00:16:18.986 --> 00:16:21.096 A:middle
and we're setting that
as the control time base

329
00:16:21.096 --> 00:16:22.716 A:middle
on our
AVSampleBufferDisplayLayer.

330
00:16:24.056 --> 00:16:26.016 A:middle
Here, we're setting the
time base time to five,

331
00:16:26.056 --> 00:16:29.146 A:middle
which would mean our frame
whose time stamp is five will be

332
00:16:29.146 --> 00:16:31.916 A:middle
displayed in our layer,
and then we go ahead

333
00:16:31.916 --> 00:16:33.676 A:middle
and set the time
base rate to one,

334
00:16:34.046 --> 00:16:36.266 A:middle
and now our time base begins
moving at the same rate

335
00:16:36.266 --> 00:16:38.936 A:middle
as the host time clock,

336
00:16:39.476 --> 00:16:42.186 A:middle
and subsequent frames
will be displayed

337
00:16:42.186 --> 00:16:44.616 A:middle
at the appropriate time.

338
00:16:45.636 --> 00:16:46.466 A:middle
All right.

339
00:16:47.706 --> 00:16:50.956 A:middle
So providing the
CMSampleBuffers,

340
00:16:50.956 --> 00:16:52.426 A:middle
the SampleBufferDisplayLayer,

341
00:16:52.626 --> 00:16:54.826 A:middle
there's really two
major scenarios

342
00:16:54.826 --> 00:16:55.746 A:middle
that can describe this.

343
00:16:56.446 --> 00:16:58.226 A:middle
First off, there's
the periodic source.

344
00:16:58.486 --> 00:16:59.966 A:middle
This is the case where
you're getting frames

345
00:16:59.966 --> 00:17:03.026 A:middle
in at basically the same rate
at which they're being displayed

346
00:17:03.026 --> 00:17:05.556 A:middle
in the
AVSampleBufferDisplayLayer.

347
00:17:06.086 --> 00:17:08.336 A:middle
This would be the case
for a live streaming app

348
00:17:08.896 --> 00:17:12.195 A:middle
or live streaming
app with low latency

349
00:17:12.195 --> 00:17:14.066 A:middle
or video conferencing scenario.

350
00:17:15.175 --> 00:17:17.626 A:middle
The next case is the
unconstrained source.

351
00:17:18.056 --> 00:17:22.215 A:middle
This is the case where you have
a large set of CMSampleBuffers

352
00:17:22.215 --> 00:17:23.576 A:middle
at your disposal ready to feed

353
00:17:23.576 --> 00:17:26.415 A:middle
into the
AVSampleBufferDisplayLayer

354
00:17:26.756 --> 00:17:27.445 A:middle
at one time.

355
00:17:28.756 --> 00:17:31.076 A:middle
This would be the case
if you have a large cache

356
00:17:31.076 --> 00:17:32.446 A:middle
of buffered network data

357
00:17:32.816 --> 00:17:35.136 A:middle
or if you're reading the
CMSampleBuffers from a file.

358
00:17:35.926 --> 00:17:38.246 A:middle
All right, let's talk
about the first case.

359
00:17:39.066 --> 00:17:40.066 A:middle
This is really simple.

360
00:17:40.166 --> 00:17:41.366 A:middle
Frames are coming
in at the same rate

361
00:17:41.366 --> 00:17:42.456 A:middle
at which they're
being displayed.

362
00:17:42.786 --> 00:17:45.306 A:middle
You can go ahead and just
enqueue the sample buffers

363
00:17:45.446 --> 00:17:47.446 A:middle
with your
AVSampleBufferDisplayLayer

364
00:17:47.446 --> 00:17:48.206 A:middle
as they arrive.

365
00:17:50.166 --> 00:17:52.096 A:middle
You use the enqueueSampleBuffer
column.

366
00:17:52.576 --> 00:17:53.756 A:middle
All right.

367
00:17:53.756 --> 00:17:56.006 A:middle
The unconstrained source is a
little bit more complicated.

368
00:17:56.206 --> 00:17:59.056 A:middle
You don't want to just shove
all of those CMSampleBuffers

369
00:17:59.056 --> 00:18:00.446 A:middle
into the
AVSampleBufferDisplayLayer

370
00:18:00.446 --> 00:18:00.836 A:middle
at once.

371
00:18:01.456 --> 00:18:02.956 A:middle
No one will be happy with that.

372
00:18:03.706 --> 00:18:05.136 A:middle
What you want to do,

373
00:18:05.226 --> 00:18:10.416 A:middle
the AVSampleBufferDisplayLayer
can tell you when its buffers,

374
00:18:10.996 --> 00:18:13.196 A:middle
internal buffers are low
and it needs more data

375
00:18:13.776 --> 00:18:15.806 A:middle
and you can ask it when
it has enough data.

376
00:18:16.856 --> 00:18:20.946 A:middle
The way you do this is
using the requestMediaData

377
00:18:20.946 --> 00:18:22.076 A:middle
WhenReadyOnQueue.

378
00:18:23.236 --> 00:18:26.716 A:middle
You provide a block
in this interface

379
00:18:27.136 --> 00:18:31.156 A:middle
and AVSampleBufferDisplayLayer
will call your block every time

380
00:18:31.216 --> 00:18:34.346 A:middle
its internal queue's are
low and it needs more data.

381
00:18:36.576 --> 00:18:38.646 A:middle
Inside of that block,
you can go ahead

382
00:18:38.646 --> 00:18:43.096 A:middle
and loop while you're asking
whether it has enough data.

383
00:18:43.206 --> 00:18:45.816 A:middle
You use isReadyForMoreMediaData
column.

384
00:18:46.296 --> 00:18:49.166 A:middle
If it returns true, that means
it wants for SampleBuffers,

385
00:18:49.306 --> 00:18:51.126 A:middle
so you keep on feeding
SampleBuffers in.

386
00:18:51.316 --> 00:18:53.246 A:middle
As soon as it returns false,

387
00:18:53.246 --> 00:18:55.226 A:middle
that means it has
enough and you can stop.

388
00:18:56.226 --> 00:18:58.656 A:middle
So it's a pretty
simple loop to write.

389
00:19:00.276 --> 00:19:01.456 A:middle
All right.

390
00:19:02.476 --> 00:19:04.466 A:middle
Let's do a quick
summary of what we talked

391
00:19:04.466 --> 00:19:06.106 A:middle
about with
AVSampleBufferDisplayLayer.

392
00:19:06.226 --> 00:19:08.356 A:middle
At this point, you
should be able

393
00:19:08.356 --> 00:19:10.426 A:middle
to create an
AVSampleBufferDisplayLayer.

394
00:19:11.716 --> 00:19:14.396 A:middle
You've learned how to
convert your Elementary Stream

395
00:19:14.616 --> 00:19:17.676 A:middle
to H.264 data into
CMSampleBuffers

396
00:19:17.726 --> 00:19:20.376 A:middle
that will happily
be decompressed

397
00:19:20.376 --> 00:19:21.926 A:middle
by your
AVSampleBufferDisplayLayer.

398
00:19:23.886 --> 00:19:26.006 A:middle
We've talked about a
couple of scenarios

399
00:19:26.286 --> 00:19:28.796 A:middle
about how you would provide
these CMSampleBuffers

400
00:19:28.836 --> 00:19:31.406 A:middle
to your layer,
AVSampleBufferDisplayLayer.

401
00:19:31.786 --> 00:19:34.386 A:middle
And finally, we talked about
using a custom time base

402
00:19:34.386 --> 00:19:35.966 A:middle
with the
AVSampleBufferDisplayLayer.

403
00:19:36.596 --> 00:19:37.626 A:middle
All right.

404
00:19:38.476 --> 00:19:40.116 A:middle
So let's dive into
our second case.

405
00:19:40.436 --> 00:19:43.296 A:middle
This is the case where you have
a stream of H.264 data coming

406
00:19:43.296 --> 00:19:44.946 A:middle
in over the network,
but you don't want

407
00:19:44.946 --> 00:19:46.296 A:middle
to just display it
in your application.

408
00:19:46.296 --> 00:19:48.066 A:middle
You want to actually
decode those frames

409
00:19:48.066 --> 00:19:50.766 A:middle
and get the decompressed
pixel buffers.

410
00:19:52.416 --> 00:19:55.666 A:middle
So what we had

411
00:19:55.666 --> 00:19:57.886 A:middle
in AVSampleBufferDisplayLayer
contains a lot

412
00:19:57.886 --> 00:19:58.756 A:middle
of the pieces we need.

413
00:19:59.656 --> 00:20:01.886 A:middle
But instead of accessing
the video decoder

414
00:20:01.886 --> 00:20:03.646 A:middle
through the
AVSampleBufferDisplayLayer,

415
00:20:04.166 --> 00:20:06.616 A:middle
we'll access it through
the VTDecompressionSession.

416
00:20:07.386 --> 00:20:10.126 A:middle
Like the
AVSampleBufferDisplayLayer,

417
00:20:10.236 --> 00:20:13.836 A:middle
VTDecompressionSession wants
CMSampleBuffers as its input.

418
00:20:15.946 --> 00:20:18.196 A:middle
And it will decode
the CMSampleBuffers

419
00:20:18.196 --> 00:20:20.796 A:middle
to CVPixelBuffers
and receive those

420
00:20:20.796 --> 00:20:22.866 A:middle
in the output callback
that you implement.

421
00:20:24.166 --> 00:20:26.766 A:middle
So in order to create a
VTDecompressionSession,

422
00:20:26.766 --> 00:20:27.796 A:middle
you'll need a few things.

423
00:20:28.626 --> 00:20:30.376 A:middle
First, you need to
provide a description

424
00:20:30.376 --> 00:20:32.506 A:middle
of the source buffers that
you'll be decompressing.

425
00:20:33.386 --> 00:20:35.256 A:middle
This is a
CMVideoFormatDescription.

426
00:20:35.306 --> 00:20:39.426 A:middle
If you're decompressing from an
Elementary Stream you've created

427
00:20:39.426 --> 00:20:40.576 A:middle
this from your parameter sets,

428
00:20:41.006 --> 00:20:43.046 A:middle
if you just have a
CMSampleBuffer that you want

429
00:20:43.046 --> 00:20:46.026 A:middle
to decompress you can pull it
right off the CMSampleBuffer.

430
00:20:47.916 --> 00:20:49.726 A:middle
Next, you need to
describe your requirements

431
00:20:49.726 --> 00:20:51.306 A:middle
for your output pixel buffers.

432
00:20:51.986 --> 00:20:55.086 A:middle
You use a pixelBufferAttributes
dictionary for this.

433
00:20:56.696 --> 00:20:57.706 A:middle
And finally, you need

434
00:20:57.706 --> 00:21:00.406 A:middle
to implement a
VTDecompressionOutputCallback.

435
00:21:01.226 --> 00:21:02.346 A:middle
All right.

436
00:21:02.566 --> 00:21:04.446 A:middle
Let's talk about
describing your requirements

437
00:21:04.446 --> 00:21:06.286 A:middle
for the Output PixelBuffers.

438
00:21:07.006 --> 00:21:08.906 A:middle
Here, you need to create
a PixelBufferAttributes

439
00:21:08.906 --> 00:21:09.426 A:middle
dictionary.

440
00:21:09.926 --> 00:21:12.726 A:middle
So let's look at a
scenario where we want

441
00:21:12.886 --> 00:21:14.936 A:middle
to use the Output CVPixelBuffers

442
00:21:14.936 --> 00:21:16.886 A:middle
in an open GLS ES
render pipeline.

443
00:21:18.406 --> 00:21:20.336 A:middle
Really, the only
requirement here that we have

444
00:21:20.336 --> 00:21:21.796 A:middle
for our Output PixelBuffers is

445
00:21:21.796 --> 00:21:23.746 A:middle
that they be OpenGL
ES compatible.

446
00:21:24.416 --> 00:21:28.336 A:middle
So we can go ahead and
just create a CF dictionary

447
00:21:28.336 --> 00:21:32.016 A:middle
or NS dictionary specifying
the kCVPixelBufferOpen

448
00:21:32.016 --> 00:21:37.976 A:middle
GLESCompatibilityKey
and set it to true.

449
00:21:38.826 --> 00:21:40.826 A:middle
So it can be very tempting

450
00:21:41.046 --> 00:21:42.926 A:middle
to when you're creating
these PixelBufferAttributes

451
00:21:42.926 --> 00:21:44.636 A:middle
dictionaries to be
very specific.

452
00:21:45.226 --> 00:21:47.256 A:middle
That way, there's no
surprises about what you get

453
00:21:47.256 --> 00:21:48.786 A:middle
out of the
VTDecompressionSession,

454
00:21:49.126 --> 00:21:50.326 A:middle
but there's some pitfalls here.

455
00:21:50.966 --> 00:21:52.506 A:middle
So let's look at this case

456
00:21:52.506 --> 00:21:56.446 A:middle
where we had kCVPixelBufferOpen
GLESCompatibilityKey set

457
00:21:56.446 --> 00:21:56.876 A:middle
to true.

458
00:21:58.126 --> 00:22:00.936 A:middle
Here, our decompression
session, the decoder inside

459
00:22:00.936 --> 00:22:03.256 A:middle
of our decompression session is
going to be decoding the frames

460
00:22:03.256 --> 00:22:05.736 A:middle
and outputting YUV
CVPixelBuffers.

461
00:22:06.966 --> 00:22:10.736 A:middle
In the VTDecompressionSession
will then ask is this --

462
00:22:11.146 --> 00:22:14.006 A:middle
well, it'll ask itself, is
this PixelBuffer compatible

463
00:22:14.006 --> 00:22:16.066 A:middle
with those requested attributes.

464
00:22:16.696 --> 00:22:17.686 A:middle
And the answer is yes.

465
00:22:17.876 --> 00:22:21.016 A:middle
That YUV frame is OpenGL ES
compatible so it can return

466
00:22:21.016 --> 00:22:22.336 A:middle
that directly to your callback.

467
00:22:23.596 --> 00:22:28.796 A:middle
But let's say you were
possessed to add BGRA request

468
00:22:28.896 --> 00:22:30.536 A:middle
to your PixelBufferAttributes.

469
00:22:31.446 --> 00:22:35.086 A:middle
So just like before,
the decoder inside

470
00:22:35.086 --> 00:22:38.066 A:middle
of our VTDecompressionSession
will decode to a YUV format

471
00:22:38.066 --> 00:22:42.336 A:middle
and will ask whether this
CVPixelBuffer is compatible

472
00:22:42.336 --> 00:22:44.186 A:middle
with the requested
output requirements.

473
00:22:44.986 --> 00:22:48.626 A:middle
And it is OpenGL ES compatible,
but it's certainly not BGRA.

474
00:22:49.716 --> 00:22:52.616 A:middle
So it will need to do an
extra buffer copy to convert

475
00:22:52.616 --> 00:22:54.446 A:middle
that YUV data to BGRA data.

476
00:22:56.616 --> 00:22:59.056 A:middle
So extra buffer copies are bad.

477
00:22:59.296 --> 00:23:02.856 A:middle
They decrease efficiency
and they can lead

478
00:23:02.986 --> 00:23:04.686 A:middle
to decreased battery life.

479
00:23:05.086 --> 00:23:08.456 A:middle
So the moral story here is
be it -- don't over specify.

480
00:23:09.796 --> 00:23:12.776 A:middle
All right, so let's talk
about your Output Callback.

481
00:23:14.276 --> 00:23:15.956 A:middle
So the Output Callback is

482
00:23:15.956 --> 00:23:18.576 A:middle
where you'll receive the
decoded CVPixelBuffers

483
00:23:19.736 --> 00:23:23.196 A:middle
and CVPixelBuffers don't
have a built in time stamp,

484
00:23:23.196 --> 00:23:25.496 A:middle
so you'll receive the
presentation time stamp

485
00:23:26.356 --> 00:23:27.726 A:middle
for that PixelBuffer here.

486
00:23:28.876 --> 00:23:32.426 A:middle
And if there are errors or the
frame is dropped for any reason,

487
00:23:32.426 --> 00:23:34.556 A:middle
you'll receive that information
in the Output Callback.

488
00:23:34.696 --> 00:23:35.866 A:middle
And it's important to note

489
00:23:35.866 --> 00:23:38.786 A:middle
that the Output Callback will
be called for every single frame

490
00:23:38.786 --> 00:23:41.786 A:middle
that you push into the
VTDecompressionSession even

491
00:23:41.786 --> 00:23:43.556 A:middle
if there's an error,
even if it's dropped.

492
00:23:45.556 --> 00:23:48.386 A:middle
All right, let's talk
about providing frames

493
00:23:48.436 --> 00:23:50.106 A:middle
to your VTDecompressionSession.

494
00:23:50.746 --> 00:23:53.666 A:middle
To do that, you call
VTDecompression

495
00:23:53.666 --> 00:23:54.896 A:middle
SessionDecodeFrame.

496
00:23:56.336 --> 00:23:58.236 A:middle
Just like
AVSampleBufferDisplayLayer,

497
00:23:58.526 --> 00:24:03.306 A:middle
you need to provide these as
CMSampleBuffers, and you need

498
00:24:03.306 --> 00:24:05.196 A:middle
to provide these
frames in decode order.

499
00:24:07.726 --> 00:24:08.906 A:middle
And by default,

500
00:24:08.906 --> 00:24:11.256 A:middle
VTDecompressionSession
DecodeFrame will

501
00:24:11.256 --> 00:24:12.416 A:middle
operate synchronously.

502
00:24:12.736 --> 00:24:15.906 A:middle
This means that your Output
Callback will be called before

503
00:24:15.906 --> 00:24:18.976 A:middle
VTDecompression
SessionDecodeFrame returns.

504
00:24:20.526 --> 00:24:22.746 A:middle
If you want a synchronous
operation, you can pass

505
00:24:22.746 --> 00:24:25.556 A:middle
in the flag requesting
EnableASynchronous

506
00:24:25.586 --> 00:24:26.346 A:middle
Decompression.

507
00:24:26.896 --> 00:24:32.256 A:middle
All right, let's talk about
Asynchronous Decompression then.

508
00:24:32.256 --> 00:24:33.546 A:middle
With ASynchronousDecompression,

509
00:24:33.856 --> 00:24:34.346 A:middle
the call

510
00:24:34.346 --> 00:24:37.696 A:middle
to VTDecompressionSession
DecodeFrame returns as soon

511
00:24:37.696 --> 00:24:40.196 A:middle
as it hands the frame
off to the decoder.

512
00:24:40.656 --> 00:24:44.726 A:middle
But decoders often have limited
pipelines for decoding frames.

513
00:24:45.446 --> 00:24:48.566 A:middle
So when the decoders
internal pipeline is full,

514
00:24:48.566 --> 00:24:51.966 A:middle
the call to VTDecompression
SessionDecodeFrame will block

515
00:24:52.306 --> 00:24:54.656 A:middle
until space opens up in
the decoders pipeline.

516
00:24:56.246 --> 00:24:57.756 A:middle
We call this decoder
back pressure.

517
00:24:58.896 --> 00:25:01.996 A:middle
So what this means is that
even though you're calling

518
00:25:02.086 --> 00:25:04.186 A:middle
VTDecompressionSession
DecodeFrame

519
00:25:04.186 --> 00:25:06.096 A:middle
and requesting Asynchronous
Decompression,

520
00:25:06.356 --> 00:25:09.316 A:middle
we will be doing the
decompression asynchronously

521
00:25:09.396 --> 00:25:14.336 A:middle
but the call can still block in
some cases, so be aware of that.

522
00:25:14.336 --> 00:25:15.796 A:middle
You're doing
ASynchronousDecompression

523
00:25:15.796 --> 00:25:19.546 A:middle
but the call can block, so don't
perform UI tasks on that thread.

524
00:25:20.766 --> 00:25:24.616 A:middle
All right, if you find yourself
in a situation where you want

525
00:25:24.616 --> 00:25:26.746 A:middle
to ensure that all asynchronous
frames have been cleared

526
00:25:26.746 --> 00:25:31.416 A:middle
out of the decoder, you can call
VTDecompressionSession and wait

527
00:25:31.416 --> 00:25:32.496 A:middle
for asynchronous frames.

528
00:25:32.996 --> 00:25:35.666 A:middle
This call will not return until
all frames have been omitted

529
00:25:35.666 --> 00:25:36.996 A:middle
from the decompression session.

530
00:25:39.876 --> 00:25:43.956 A:middle
So sometimes, we'll be decode
in a sequence of video frames.

531
00:25:44.466 --> 00:25:46.956 A:middle
There will be a change in
the CMVideoFormatDescription,

532
00:25:47.156 --> 00:25:50.086 A:middle
so let's look at the case
where we had a sequence

533
00:25:50.086 --> 00:25:51.666 A:middle
of an Elementary Stream

534
00:25:51.666 --> 00:25:53.946 A:middle
and we created the
first format description

535
00:25:53.946 --> 00:25:56.186 A:middle
out of the first parameter
sets that we encountered.

536
00:25:56.386 --> 00:25:58.166 A:middle
So now we have format
description one

537
00:25:58.306 --> 00:25:59.946 A:middle
with our first SPS and PPS.

538
00:25:59.946 --> 00:26:04.126 A:middle
We can go ahead and create
our VTDecompressionSession

539
00:26:04.126 --> 00:26:07.856 A:middle
with that format description and
decode all the subsequent frames

540
00:26:08.036 --> 00:26:10.706 A:middle
with that format description
attached to the CMSampleBuffer

541
00:26:11.956 --> 00:26:16.826 A:middle
until we encounter a new
SPS and PPS in the stream.

542
00:26:17.886 --> 00:26:20.266 A:middle
Then, we need to create
a new format description

543
00:26:20.266 --> 00:26:24.496 A:middle
with the new SPS and PPS
and we have to make sure

544
00:26:24.496 --> 00:26:26.726 A:middle
that the decompression
session can switch

545
00:26:26.726 --> 00:26:28.186 A:middle
between these format
descriptions.

546
00:26:29.316 --> 00:26:32.966 A:middle
So to do that, you call
VTDecompressionSession

547
00:26:32.966 --> 00:26:34.596 A:middle
CanAcceptFormatDescription.

548
00:26:35.296 --> 00:26:37.926 A:middle
This will ensure -- ask the
decoder whether it's able

549
00:26:37.926 --> 00:26:39.856 A:middle
to transition from
FormatDescription one

550
00:26:39.856 --> 00:26:42.826 A:middle
to FormatDescription two.

551
00:26:43.366 --> 00:26:46.116 A:middle
If the answer is true, yes,

552
00:26:46.116 --> 00:26:49.776 A:middle
it can handle the new
accepted FormatDescription.

553
00:26:50.146 --> 00:26:52.226 A:middle
That means you can
pass subsequent samples

554
00:26:52.226 --> 00:26:54.346 A:middle
with that new FormatDescription
attached to them

555
00:26:54.946 --> 00:26:57.806 A:middle
into the Decompression Session
and everything will work fine.

556
00:26:58.186 --> 00:27:02.066 A:middle
If it returns false that
means the decompressor cannot

557
00:27:02.066 --> 00:27:04.696 A:middle
transition from that
first format description

558
00:27:04.946 --> 00:27:07.236 A:middle
to the second format
description, and you'll need

559
00:27:07.236 --> 00:27:09.236 A:middle
to create a new
VTDecompressionSession

560
00:27:09.966 --> 00:27:13.566 A:middle
and be sure and pass the
new frames into that one.

561
00:27:14.326 --> 00:27:17.266 A:middle
And be sure to release that
old VTDecompressionSession

562
00:27:17.796 --> 00:27:20.256 A:middle
when you're no longer using it.

563
00:27:20.816 --> 00:27:21.296 A:middle
All right.

564
00:27:21.976 --> 00:27:23.076 A:middle
Quick summary of what we talked

565
00:27:23.076 --> 00:27:24.746 A:middle
about with the
VTDecompressionSession.

566
00:27:25.586 --> 00:27:30.166 A:middle
We talked creating the
VTDecompressionSession and how

567
00:27:30.166 --> 00:27:31.446 A:middle
to make optimal decisions

568
00:27:31.446 --> 00:27:35.356 A:middle
when creating the
PixelBufferAttributes dictionary

569
00:27:36.326 --> 00:27:38.996 A:middle
for specifying your
output requirements.

570
00:27:39.616 --> 00:27:43.046 A:middle
We talked about running your
decompression session both

571
00:27:43.046 --> 00:27:46.426 A:middle
synchronously and
asynchronously and we talked

572
00:27:46.426 --> 00:27:49.106 A:middle
about handing changes in
CMVideo FormatDescription.

573
00:27:50.846 --> 00:27:53.886 A:middle
So with that, let's
hop into case three.

574
00:27:54.446 --> 00:27:59.686 A:middle
This is the case where you
have a stream of CVPixelBuffers

575
00:27:59.686 --> 00:28:02.566 A:middle
or frames coming in from a
camera or another source,

576
00:28:03.296 --> 00:28:05.786 A:middle
and you want to compress those
directly into a movie file.

577
00:28:07.136 --> 00:28:10.216 A:middle
Well, for this, you may be
familiar with this already.

578
00:28:10.326 --> 00:28:11.726 A:middle
We have AVAssetWriter.

579
00:28:13.306 --> 00:28:16.626 A:middle
AVAssetWriter has an encoder
internally, and it's going

580
00:28:16.626 --> 00:28:19.196 A:middle
to be encoding those
frames into CMSampleBuffers

581
00:28:20.046 --> 00:28:22.086 A:middle
and it's got some
file writing smarts,

582
00:28:22.196 --> 00:28:25.066 A:middle
so it can write these
optimally into a movie file.

583
00:28:25.896 --> 00:28:30.056 A:middle
We're not actually going
to talk more at this point

584
00:28:30.056 --> 00:28:34.326 A:middle
about AVAssetWriter, but
it's an important concept

585
00:28:34.326 --> 00:28:36.396 A:middle
and an important thing to bring
up in the context of this talk,

586
00:28:36.596 --> 00:28:39.446 A:middle
so if you want more information
on the AVAssetWriter,

587
00:28:39.546 --> 00:28:45.506 A:middle
you can go back to WWDC 2013
and the talk Moving to AVKit

588
00:28:45.506 --> 00:28:48.086 A:middle
and AVFoundation or 2011,

589
00:28:48.766 --> 00:28:50.736 A:middle
Working with Media
and AVFoundation.

590
00:28:51.756 --> 00:28:53.856 A:middle
All right.

591
00:28:54.236 --> 00:28:56.086 A:middle
Let's just hop straight
into case four.

592
00:28:56.466 --> 00:28:59.886 A:middle
This is the case where you
have that stream of data coming

593
00:28:59.886 --> 00:29:03.156 A:middle
in from your camera and
you want to compress it,

594
00:29:03.156 --> 00:29:04.906 A:middle
but you don't want to
write into a movie file.

595
00:29:05.046 --> 00:29:07.656 A:middle
You want direct access to
those compresses SampleBuffers.

596
00:29:08.896 --> 00:29:11.486 A:middle
So we want to approach
our video encoder

597
00:29:11.986 --> 00:29:14.446 A:middle
through a VTCompressionSession
rather

598
00:29:14.446 --> 00:29:15.706 A:middle
than through the AVAssetWriter.

599
00:29:17.316 --> 00:29:18.976 A:middle
So just like AVAssetWriter,

600
00:29:18.976 --> 00:29:21.946 A:middle
VTCompressionSession takes
CVPixelBuffers as its input,

601
00:29:22.726 --> 00:29:25.586 A:middle
and it's going to compress those
and return CMSampleBuffers,

602
00:29:25.876 --> 00:29:27.336 A:middle
and we can go ahead and send

603
00:29:27.716 --> 00:29:29.376 A:middle
that compressed data
out over the network.

604
00:29:30.736 --> 00:29:34.156 A:middle
So to create a
VTCompressionSession,

605
00:29:34.156 --> 00:29:36.826 A:middle
you'll need a few things,
and this is really simple.

606
00:29:37.206 --> 00:29:39.296 A:middle
You just need to specify
the dimensions you want

607
00:29:39.296 --> 00:29:40.516 A:middle
for your compressed output.

608
00:29:41.616 --> 00:29:44.816 A:middle
You need to tell us what format
you want to compress to such

609
00:29:44.816 --> 00:29:51.826 A:middle
as kCMVideoCodecTypeH.264 and
you can optionally provide a set

610
00:29:51.826 --> 00:29:54.316 A:middle
of PixelBufferAttributes
describing your source

611
00:29:54.476 --> 00:29:56.326 A:middle
CVPixelBuffers that
you'll be sending

612
00:29:56.326 --> 00:29:56.976 A:middle
to the VTCompressionSession.

613
00:29:57.106 --> 00:29:59.966 A:middle
And finally, you need

614
00:29:59.966 --> 00:30:02.346 A:middle
to implement a
VTCompressionOutput Callback.

615
00:30:04.386 --> 00:30:07.336 A:middle
So you've created a
VTCompressionSession.

616
00:30:07.626 --> 00:30:09.356 A:middle
Now you want to configure it.

617
00:30:10.386 --> 00:30:12.476 A:middle
You configure a
VTCompressionSession using

618
00:30:12.476 --> 00:30:14.166 A:middle
VTSession SetProperty.

619
00:30:14.666 --> 00:30:17.316 A:middle
In fact, you can
have a whole sequence

620
00:30:17.316 --> 00:30:19.516 A:middle
of VTSessionSetProperty calls.

621
00:30:19.596 --> 00:30:24.076 A:middle
So I'm going to go through a
few common properties here and

622
00:30:24.676 --> 00:30:26.226 A:middle
but this is not an
exhaustive list.

623
00:30:26.876 --> 00:30:29.216 A:middle
The first one I'm going to
mention is AllowFrameReordering.

624
00:30:29.216 --> 00:30:33.816 A:middle
By default, H.264 encoder will
allow frames to be reordered.

625
00:30:34.286 --> 00:30:36.826 A:middle
That means the presentation
time stamp that you pass them

626
00:30:36.826 --> 00:30:41.116 A:middle
in will not necessarily
equal the decode order

627
00:30:41.376 --> 00:30:42.576 A:middle
in which they're admitted.

628
00:30:43.446 --> 00:30:46.926 A:middle
If you want to disable this
behavior, you can pass false

629
00:30:47.266 --> 00:30:48.456 A:middle
to allow frame reordering.

630
00:30:50.426 --> 00:30:51.936 A:middle
Next one, average byte rate.

631
00:30:52.386 --> 00:30:54.916 A:middle
This is how you set a target
byte rate for the compressor.

632
00:30:56.186 --> 00:31:03.416 A:middle
H.264EntropyMode; using this,
you can specify CALV compression

633
00:31:03.416 --> 00:31:06.616 A:middle
or KVTH compression
for your H.264 encoder.

634
00:31:07.436 --> 00:31:10.306 A:middle
All right, and then there's
the RealTime property.

635
00:31:10.956 --> 00:31:13.396 A:middle
The RealTime property allows
you to tell the encoder

636
00:31:13.396 --> 00:31:16.786 A:middle
that this is a real time
encoding operation such as

637
00:31:16.786 --> 00:31:22.166 A:middle
in a live streaming case,
conferencing case as opposed

638
00:31:22.166 --> 00:31:26.636 A:middle
to more of a background activity
like a transcode operation.

639
00:31:27.426 --> 00:31:30.256 A:middle
And the final one I'm going

640
00:31:30.256 --> 00:31:32.276 A:middle
to mention here is
the ProfileLevelKey.

641
00:31:32.756 --> 00:31:35.726 A:middle
This allows you to specify
specific profiles and levels

642
00:31:35.826 --> 00:31:39.236 A:middle
or specific profiles and allow
us to choose the correct level.

643
00:31:39.816 --> 00:31:43.366 A:middle
And this is definitely
not an exhaustive list.

644
00:31:43.456 --> 00:31:48.006 A:middle
There's a lot of these options
available, so go ahead and look

645
00:31:48.006 --> 00:31:52.316 A:middle
in VTCompressionProperties.H
and see what we have for you.

646
00:31:52.316 --> 00:31:57.006 A:middle
All right, let's talk about
providing CVPixelBuffers

647
00:31:57.006 --> 00:31:58.376 A:middle
to your VTCompressionSession.

648
00:31:59.406 --> 00:32:01.576 A:middle
Use
VTCompressionSessionEncodeFrame

649
00:32:01.576 --> 00:32:07.556 A:middle
to do this, and you'll need
to provide CVPixelBuffers

650
00:32:08.106 --> 00:32:10.066 A:middle
and as I've mentioned,

651
00:32:10.066 --> 00:32:14.076 A:middle
CVPixelBuffers don't have a
presentation timestamp built

652
00:32:14.076 --> 00:32:16.286 A:middle
into them, so as a
separate parameter,

653
00:32:16.286 --> 00:32:18.096 A:middle
you'll provide the
presentation timestamp.

654
00:32:19.626 --> 00:32:23.576 A:middle
You need to feed the frames
in in presentation order.

655
00:32:25.996 --> 00:32:30.746 A:middle
And it's one more note about
the presentation order, they --

656
00:32:31.106 --> 00:32:33.496 A:middle
the presentation timestamps
must be increasing.

657
00:32:33.926 --> 00:32:36.236 A:middle
No duplicate presentation
timestamps,

658
00:32:36.576 --> 00:32:38.066 A:middle
no timestamps that go backwards.

659
00:32:39.736 --> 00:32:42.146 A:middle
And so compression sessions,

660
00:32:42.326 --> 00:32:45.866 A:middle
compressions operations usually
require a window or frames

661
00:32:45.866 --> 00:32:49.046 A:middle
that they'll operate on, so
your output may be delayed.

662
00:32:49.756 --> 00:32:52.916 A:middle
So you may not receive
a compressed frame

663
00:32:52.916 --> 00:32:54.716 A:middle
in your Output Callback
until a certain number

664
00:32:54.716 --> 00:32:56.556 A:middle
of frames have been
pushed into the encoder.

665
00:32:57.116 --> 00:32:59.476 A:middle
All right.

666
00:32:59.476 --> 00:33:01.946 A:middle
And finally, if you've
reached the end of the frames

667
00:33:01.946 --> 00:33:04.196 A:middle
that you're passing to the
compression session and you want

668
00:33:04.876 --> 00:33:07.606 A:middle
to have it emit all of the
frames that it's received

669
00:33:07.606 --> 00:33:10.106 A:middle
so far, you can use
VTCompressionSession

670
00:33:10.106 --> 00:33:11.096 A:middle
CompleteFrames.

671
00:33:11.436 --> 00:33:12.956 A:middle
All pending frames
will be omitted.

672
00:33:14.896 --> 00:33:15.376 A:middle
All right.

673
00:33:15.706 --> 00:33:17.336 A:middle
Let's talk about
your Output Callback.

674
00:33:19.296 --> 00:33:20.426 A:middle
So your Output Callback is

675
00:33:20.426 --> 00:33:23.276 A:middle
where you'll receive your
output CMSampleBuffers.

676
00:33:23.426 --> 00:33:25.126 A:middle
These contain the
compressed frames.

677
00:33:25.976 --> 00:33:29.476 A:middle
If there were any errors or
dropped frames, you'll receive

678
00:33:29.476 --> 00:33:30.526 A:middle
that information here.

679
00:33:31.466 --> 00:33:34.786 A:middle
And final thing, frames will
be omitted in decode order.

680
00:33:35.006 --> 00:33:37.436 A:middle
So you provided frames to
the VTCompressionSession

681
00:33:37.436 --> 00:33:38.446 A:middle
in presentation order

682
00:33:38.856 --> 00:33:40.716 A:middle
and they'll be omitted
in decode order.

683
00:33:41.456 --> 00:33:44.486 A:middle
All right.

684
00:33:45.176 --> 00:33:48.136 A:middle
Well, so you've compressed
a bunch of frames.

685
00:33:48.306 --> 00:33:51.516 A:middle
They're now compressed
in CMSampleBuffers,

686
00:33:51.516 --> 00:33:54.876 A:middle
which means that they're
using MPEG-4 packaging.

687
00:33:55.646 --> 00:33:57.696 A:middle
And you want to send that
out over the network,

688
00:33:58.036 --> 00:34:01.576 A:middle
which means you may
need to switch these

689
00:34:01.576 --> 00:34:03.416 A:middle
over to Elementary
Stream packaging.

690
00:34:04.346 --> 00:34:05.866 A:middle
Well, once again,
you're going to have

691
00:34:05.866 --> 00:34:08.025 A:middle
to do a little bit of work.

692
00:34:09.096 --> 00:34:12.196 A:middle
So we talked about the
parameter sets before.

693
00:34:13.025 --> 00:34:16.626 A:middle
So the parameters sets will
in your MPEG-4 package,

694
00:34:16.626 --> 00:34:20.315 A:middle
H.264 will be in the
CMVideoFormatDescription.

695
00:34:21.076 --> 00:34:22.335 A:middle
So the first thing
you're going to have

696
00:34:22.335 --> 00:34:25.866 A:middle
to do is extract those
parameter sets and package them

697
00:34:25.866 --> 00:34:27.766 A:middle
as NAL Units to send
out over the network.

698
00:34:29.716 --> 00:34:33.686 A:middle
Well, we provide a handy
utility for that too.

699
00:34:34.186 --> 00:34:38.176 A:middle
CMVideoFormatDescription
GetH.264ParameterSetAtIndex.

700
00:34:39.696 --> 00:34:44.686 A:middle
All right, and the next thing
you need to do is the opposite

701
00:34:44.686 --> 00:34:46.795 A:middle
of what we did with
AVSampleBufferDisplayLayer.

702
00:34:47.616 --> 00:34:51.666 A:middle
Our NAL Units are all going
to have length headers

703
00:34:52.585 --> 00:34:53.636 A:middle
and you're going to need

704
00:34:53.636 --> 00:34:56.835 A:middle
to convert those length
headers into start codes.

705
00:34:58.816 --> 00:35:00.966 A:middle
So as you extract each NAL Unit

706
00:35:00.966 --> 00:35:03.576 A:middle
from the compressed data
inside the CMSampleBuffer,

707
00:35:04.206 --> 00:35:06.106 A:middle
convert those headers
on the NAL Units.

708
00:35:07.736 --> 00:35:08.236 A:middle
All right.

709
00:35:08.536 --> 00:35:10.136 A:middle
Quick summary of what we talked

710
00:35:10.136 --> 00:35:11.776 A:middle
about with the
VTCompressionSession.

711
00:35:12.636 --> 00:35:15.026 A:middle
We talked about creating
the VTCompressionSession.

712
00:35:16.216 --> 00:35:17.086 A:middle
We've talked about how

713
00:35:17.086 --> 00:35:19.766 A:middle
to configure it using the
VTSessionSetProperty column.

714
00:35:21.886 --> 00:35:24.676 A:middle
And we talked about how you
would provide CVPixelBuffers

715
00:35:24.676 --> 00:35:25.996 A:middle
to the compression session.

716
00:35:27.816 --> 00:35:31.316 A:middle
And finally, we talked about
converting those CMSampleBuffers

717
00:35:31.316 --> 00:35:34.736 A:middle
into an H.264 Elementary
Stream packaging.

718
00:35:35.796 --> 00:35:36.436 A:middle
All right.

719
00:35:36.436 --> 00:35:39.126 A:middle
And with that, I'd like
to hand things off to Eric

720
00:35:39.126 --> 00:35:40.546 A:middle
so he can talk about Multi-Pass.

721
00:35:40.996 --> 00:35:43.806 A:middle
&gt;&gt; Good morning everyone.

722
00:35:43.996 --> 00:35:45.326 A:middle
My name is Eric Turnquist.

723
00:35:45.326 --> 00:35:47.486 A:middle
I'm the Core Media Engineer,
and today, I want to talk to you

724
00:35:47.486 --> 00:35:48.636 A:middle
about Multi-Pass Encoding.

725
00:35:49.606 --> 00:35:53.096 A:middle
So as a media engineer, we often
deal with two opposing forces;

726
00:35:53.326 --> 00:35:54.936 A:middle
quality versus bit rate.

727
00:35:55.536 --> 00:35:58.256 A:middle
So quality is how pristine
the image is, and we all know

728
00:35:58.256 --> 00:36:01.076 A:middle
and we've seen great quality
video and we really don't

729
00:36:01.076 --> 00:36:02.596 A:middle
like seeing bad quality video.

730
00:36:03.476 --> 00:36:05.436 A:middle
Bit rate is how much
data per time is

731
00:36:05.436 --> 00:36:06.536 A:middle
in the output media file.

732
00:36:07.076 --> 00:36:08.956 A:middle
So let's say we're
preparing some content.

733
00:36:10.636 --> 00:36:13.436 A:middle
If you're like me, you go
for high quality first.

734
00:36:13.776 --> 00:36:15.116 A:middle
So great, we have high quality.

735
00:36:16.076 --> 00:36:17.996 A:middle
Now in this case, what
happens with the bit rate?

736
00:36:18.806 --> 00:36:21.476 A:middle
Well unfortunately, if you have
high quality, you also tend

737
00:36:21.476 --> 00:36:22.436 A:middle
to have a high bit rate.

738
00:36:22.436 --> 00:36:25.116 A:middle
Now that's okay,
but not what we want

739
00:36:25.116 --> 00:36:27.486 A:middle
if we're streaming this content
or storing it on a server.

740
00:36:28.606 --> 00:36:30.446 A:middle
So in that case we
want to a low bit rate

741
00:36:30.756 --> 00:36:33.046 A:middle
but the quality isn't
going to stay this high.

742
00:36:33.826 --> 00:36:35.916 A:middle
Unfortunately, that's also
going to go down as well.

743
00:36:37.086 --> 00:36:39.936 A:middle
So we've all seen this as
block encoder artifacts

744
00:36:39.936 --> 00:36:41.846 A:middle
or an output image that
doesn't really even look

745
00:36:41.846 --> 00:36:42.626 A:middle
like the source.

746
00:36:42.716 --> 00:36:43.586 A:middle
We don't want this either.

747
00:36:44.246 --> 00:36:45.786 A:middle
Ideally, we want
something like this;

748
00:36:46.126 --> 00:36:47.856 A:middle
high quality and low bit rate.

749
00:36:48.426 --> 00:36:51.236 A:middle
In order to achieve that goal,
we've added Multi-Pass Encoding

750
00:36:51.236 --> 00:36:53.166 A:middle
to AVFoundation and
Video Toolbox.

751
00:36:53.706 --> 00:37:02.266 A:middle
Yeah, so first off, what
is Multi-Pass Encoding?

752
00:37:02.716 --> 00:37:05.786 A:middle
Well, let's do a review of what
Single-Pass Encoding is first.

753
00:37:05.786 --> 00:37:07.956 A:middle
So this is what David covered
in his portion of the talk.

754
00:37:09.146 --> 00:37:11.306 A:middle
With Single-Pass Encoding,
you have frames coming in,

755
00:37:11.456 --> 00:37:13.186 A:middle
going into the encoder
and being admitted.

756
00:37:13.466 --> 00:37:14.926 A:middle
In this case, we're
going to a movie file.

757
00:37:16.206 --> 00:37:18.996 A:middle
Then once you're done appending
all the samples, we're finished,

758
00:37:20.356 --> 00:37:21.966 A:middle
and we're left with
our output movie file.

759
00:37:22.246 --> 00:37:22.826 A:middle
Simple enough.

760
00:37:24.066 --> 00:37:25.616 A:middle
Let's see how Multi-Pass
differs.

761
00:37:25.796 --> 00:37:27.746 A:middle
So you have uncompressed
frames coming in going

762
00:37:27.746 --> 00:37:29.826 A:middle
into the compression
session, being admitted

763
00:37:29.826 --> 00:37:30.946 A:middle
as compressed samples.

764
00:37:30.946 --> 00:37:32.566 A:middle
Now we're going to change
things up a little bit.

765
00:37:33.206 --> 00:37:35.126 A:middle
So we're going to have
our frame database.

766
00:37:35.446 --> 00:37:37.076 A:middle
This will store the
compressed samples

767
00:37:37.076 --> 00:37:39.766 A:middle
and allow us random access in
replacement, which is important

768
00:37:39.766 --> 00:37:42.726 A:middle
for Multi-Pass, and we're going
to have our encoder database.

769
00:37:43.226 --> 00:37:44.976 A:middle
This will store frame analysis.

770
00:37:46.876 --> 00:37:49.066 A:middle
So we're done appending
for one pass

771
00:37:49.066 --> 00:37:52.036 A:middle
and the encoder will decide I
think I can actually do better

772
00:37:52.036 --> 00:37:54.266 A:middle
in another pass, so I can tweak
the parameters a little bit

773
00:37:54.266 --> 00:37:55.156 A:middle
to get better quality.

774
00:37:57.536 --> 00:37:59.896 A:middle
It will request some
samples and you'll go through

775
00:37:59.896 --> 00:38:01.736 A:middle
and send those samples
again to the encoder,

776
00:38:02.306 --> 00:38:06.596 A:middle
and then it may decide I'm
done or I'm actually --

777
00:38:06.596 --> 00:38:07.766 A:middle
or I want more passes.

778
00:38:07.766 --> 00:38:09.466 A:middle
In this case, let's
assume that we're finished.

779
00:38:11.016 --> 00:38:13.326 A:middle
So we no longer need
the encoder database

780
00:38:13.326 --> 00:38:14.896 A:middle
or the compression
session, but we're left

781
00:38:14.896 --> 00:38:17.246 A:middle
with this Frame Database
and we want a movie file,

782
00:38:17.546 --> 00:38:18.606 A:middle
so we need one more step.

783
00:38:19.856 --> 00:38:22.326 A:middle
There's a final copy
from the Frame Database

784
00:38:22.326 --> 00:38:25.356 A:middle
to the output movie
file and that's it.

785
00:38:25.356 --> 00:38:28.576 A:middle
We have a Multi-Pass encoded
video track on a movie file.

786
00:38:29.986 --> 00:38:32.466 A:middle
Cool. Let's go over
some encoder features.

787
00:38:33.556 --> 00:38:36.826 A:middle
So my first point is I want to
make a note of is David said

788
00:38:36.826 --> 00:38:38.716 A:middle
that Single-Pass is
hardware accelerated

789
00:38:39.056 --> 00:38:41.166 A:middle
and Multi-Pass is also
hardware accelerated,

790
00:38:41.366 --> 00:38:43.296 A:middle
so you're not losing any
hardware acceleration there.

791
00:38:46.536 --> 00:38:49.486 A:middle
Second point is that Multi-Pass
has knowledge of the future.

792
00:38:50.046 --> 00:38:52.446 A:middle
Now it's not some crazy time
traveling video encoder.

793
00:38:53.016 --> 00:38:55.226 A:middle
Bonus points whoever filed
that enhancement request.

794
00:38:55.766 --> 00:38:59.696 A:middle
It allows or is able to
see your entire content.

795
00:39:00.216 --> 00:39:03.196 A:middle
So in Single-Pass, as frames
come in, the encoder has

796
00:39:03.226 --> 00:39:05.166 A:middle
to make assumptions about
what might come next.

797
00:39:05.786 --> 00:39:07.996 A:middle
In Multi-Pass, it's already
seen all your content

798
00:39:07.996 --> 00:39:09.626 A:middle
so it can make much
better decisions there.

799
00:39:11.996 --> 00:39:14.456 A:middle
Third, it can change
decision that it's made.

800
00:39:14.716 --> 00:39:18.406 A:middle
So in Single-Pass, as soon as
the frame is emitted, that's it.

801
00:39:18.406 --> 00:39:20.066 A:middle
It can't -- it can
no longer change.

802
00:39:20.806 --> 00:39:23.986 A:middle
It can no longer change its
mind about what it's emitted.

803
00:39:24.986 --> 00:39:27.966 A:middle
In Multi-Pass, because the frame
database supports replacement,

804
00:39:28.316 --> 00:39:30.686 A:middle
each pass you can go through
and change its mind about how

805
00:39:30.686 --> 00:39:32.006 A:middle
to achieve optimal quality.

806
00:39:32.566 --> 00:39:35.046 A:middle
And as a result of this,

807
00:39:35.046 --> 00:39:37.476 A:middle
you really get optimal
quality per bit, so it's sort

808
00:39:37.476 --> 00:39:40.906 A:middle
of like having a very awesome
custom encoder for your content.

809
00:39:41.916 --> 00:39:45.246 A:middle
So that's how Multi-Pass
works and some more features.

810
00:39:45.296 --> 00:39:46.736 A:middle
Let's talk about new APIs.

811
00:39:47.966 --> 00:39:49.976 A:middle
So first off, let's
talk about AVFoundation.

812
00:39:50.636 --> 00:39:54.646 A:middle
In AVFoundation, we have a new
AVAssetExport Session property.

813
00:39:55.046 --> 00:39:57.366 A:middle
We have new pass descriptions
for AVAssetWriterInput

814
00:39:57.766 --> 00:39:59.696 A:middle
and we have reuse on
AVAssetReaderOutput.

815
00:40:00.596 --> 00:40:02.276 A:middle
So first, let's go
over an overview

816
00:40:02.276 --> 00:40:03.586 A:middle
of AVAssetExport Session.

817
00:40:04.766 --> 00:40:07.296 A:middle
In AVAsset ExportSession,
you're going from a source file,

818
00:40:07.836 --> 00:40:10.556 A:middle
decoding them then
performing some operation

819
00:40:10.556 --> 00:40:12.856 A:middle
on those uncompressed
buffers, something like scaling

820
00:40:12.856 --> 00:40:15.236 A:middle
or color conversion,
and you're encoding them

821
00:40:15.236 --> 00:40:16.496 A:middle
and writing them
to a movie file.

822
00:40:17.036 --> 00:40:19.476 A:middle
So in this case, what does
AVAsset ExportSession provide?

823
00:40:20.376 --> 00:40:21.726 A:middle
Well, it does all this for you.

824
00:40:21.896 --> 00:40:26.456 A:middle
It's the easiest way to
transcode media on iOS and OS X.

825
00:40:26.686 --> 00:40:27.906 A:middle
So let's see what
we've added here.

826
00:40:29.246 --> 00:40:31.696 A:middle
So in AVAssetExportSession
multiple passes are taken care

827
00:40:31.696 --> 00:40:33.156 A:middle
of for you automatically.

828
00:40:33.236 --> 00:40:34.836 A:middle
There's no work you have to do

829
00:40:34.836 --> 00:40:36.546 A:middle
to send the samples
between passes.

830
00:40:37.066 --> 00:40:39.926 A:middle
And also, it falls
back to Single-Pass

831
00:40:39.926 --> 00:40:41.206 A:middle
if Multi-Pass isn't supported.

832
00:40:41.586 --> 00:40:44.156 A:middle
So if you choose a
preset that uses a codec

833
00:40:44.156 --> 00:40:46.256 A:middle
where Multi-Pass isn't
supported, don't worry,

834
00:40:46.296 --> 00:40:47.296 A:middle
it'll use Single-Pass.

835
00:40:48.566 --> 00:40:50.536 A:middle
And we have one new
property, Set SDS

836
00:40:50.536 --> 00:40:53.196 A:middle
and you're automatically opted
into Multi-Task, and that's it.

837
00:40:53.666 --> 00:40:56.426 A:middle
So for a large majority of
you, this is all you need.

838
00:40:57.616 --> 00:40:59.466 A:middle
Next, let's talk
about AVSWriter.

839
00:41:00.356 --> 00:41:03.136 A:middle
So AVSWriter, you're coming
from uncompressed samples.

840
00:41:03.136 --> 00:41:05.126 A:middle
You want to compress them and
write them to a movie file.

841
00:41:06.356 --> 00:41:09.486 A:middle
You might be coming from an
OpenGL or OpenGL ES context.

842
00:41:09.826 --> 00:41:11.766 A:middle
In this case, what
does AVSWriter provide?

843
00:41:13.106 --> 00:41:15.686 A:middle
Well, it wraps this portion
going from the encoder

844
00:41:15.846 --> 00:41:17.186 A:middle
to the output movie file.

845
00:41:19.686 --> 00:41:23.406 A:middle
Another use case, it's
similar to AVSExportSession

846
00:41:23.446 --> 00:41:25.276 A:middle
where you're going from
a source movie file

847
00:41:25.346 --> 00:41:26.836 A:middle
to a destination app movie file

848
00:41:26.836 --> 00:41:28.636 A:middle
and modifying the
buffers in some way.

849
00:41:29.536 --> 00:41:32.116 A:middle
Well in this case, you're
going to use an AVSReaderOutput

850
00:41:32.116 --> 00:41:33.486 A:middle
and an AVSWriterInput.

851
00:41:33.486 --> 00:41:36.156 A:middle
You're responsible for sending
samples from one to the other.

852
00:41:36.686 --> 00:41:42.356 A:middle
Let's go over a new
AVSWriterInput APIs.

853
00:41:42.486 --> 00:41:45.566 A:middle
So like AVAssetExportSession,
you need to enable Multi-Pass,

854
00:41:46.036 --> 00:41:48.226 A:middle
so set SDS and you're
automatically opted in.

855
00:41:48.806 --> 00:41:52.356 A:middle
Then after you're done
appending samples,

856
00:41:52.726 --> 00:41:54.636 A:middle
you need to mark the
current pass as finished.

857
00:41:55.366 --> 00:41:56.326 A:middle
So what does this do?

858
00:41:56.676 --> 00:41:58.456 A:middle
Well, this triggers
the encoder analysis.

859
00:41:58.696 --> 00:42:01.756 A:middle
The encoder needs to decide if I
need to perform multiple passes

860
00:42:02.296 --> 00:42:04.916 A:middle
and if so, what time ranges.

861
00:42:05.026 --> 00:42:07.936 A:middle
So the encoder might say I want
to see the entire sequence again

862
00:42:08.156 --> 00:42:10.086 A:middle
or I want to see
subsets of the sequence.

863
00:42:11.126 --> 00:42:12.316 A:middle
So how does the encoder talk

864
00:42:12.316 --> 00:42:15.876 A:middle
about what time ranges it
wants for the next pass?

865
00:42:16.196 --> 00:42:18.576 A:middle
Well, that's through
AVSWriterInput PassDescription.

866
00:42:19.016 --> 00:42:21.826 A:middle
So in this case, we have
time from zero to three,

867
00:42:22.006 --> 00:42:25.596 A:middle
but not the sample at time
three, and samples from five

868
00:42:25.596 --> 00:42:27.606 A:middle
to seven, but not the
sample at time seven.

869
00:42:28.376 --> 00:42:32.136 A:middle
So a pass description is the
encoder's request for media

870
00:42:32.136 --> 00:42:35.686 A:middle
in the next pass, and it may
contain the entire sequence

871
00:42:35.756 --> 00:42:37.156 A:middle
or subsets of the sequence.

872
00:42:37.536 --> 00:42:41.316 A:middle
On a pass description, you
can query the time ranges

873
00:42:41.316 --> 00:42:44.046 A:middle
that the encoder has requested
by calling sourceTimeRanges.

874
00:42:47.616 --> 00:42:50.526 A:middle
All right, let's talk
about how AVSWriter uses

875
00:42:50.526 --> 00:42:51.496 A:middle
pass descriptions.

876
00:42:52.896 --> 00:42:55.626 A:middle
So when you trigger the encoder
analysis, the encoder needs

877
00:42:55.626 --> 00:42:57.836 A:middle
to reply with what
decisions it's made.

878
00:42:57.926 --> 00:43:01.396 A:middle
So you provide a block on this
method to allow the encoder

879
00:43:01.396 --> 00:43:02.926 A:middle
to give you that answer.

880
00:43:03.226 --> 00:43:05.396 A:middle
So this block is called when
the encoder makes a decision

881
00:43:05.396 --> 00:43:07.796 A:middle
about the next pass.

882
00:43:08.076 --> 00:43:10.396 A:middle
In that block, you can get
the new pass description,

883
00:43:10.396 --> 00:43:11.256 A:middle
the encoder's decision

884
00:43:11.256 --> 00:43:13.216 A:middle
about what content it
wants for the next pass.

885
00:43:13.506 --> 00:43:15.026 A:middle
Let's see how that
works all in a sample.

886
00:43:15.586 --> 00:43:18.606 A:middle
So here's our sample.

887
00:43:19.286 --> 00:43:21.116 A:middle
We have our block
callback that your provide.

888
00:43:23.036 --> 00:43:25.676 A:middle
Inside that callback you call
current pass description.

889
00:43:25.676 --> 00:43:27.876 A:middle
This asks the encoder
what time ranges it wants

890
00:43:27.876 --> 00:43:30.726 A:middle
for the next pass.

891
00:43:30.846 --> 00:43:33.626 A:middle
If the pass is none nil,
meaning the encoder wants data

892
00:43:33.626 --> 00:43:36.566 A:middle
for another pass, you
reconfigure your source.

893
00:43:36.656 --> 00:43:38.966 A:middle
So this is where the
source will send samples

894
00:43:39.316 --> 00:43:43.686 A:middle
to the AVSWriterInput, and then
you prepare the AVSWriterInput

895
00:43:43.736 --> 00:43:44.766 A:middle
for the next pass.

896
00:43:44.856 --> 00:43:45.516 A:middle
You're already familiar

897
00:43:45.516 --> 00:43:47.666 A:middle
with requestMediaDataWhen
ReadyOnQueue.

898
00:43:48.276 --> 00:43:53.036 A:middle
If the pass is nil, that means
the encoder has finished passes.

899
00:43:53.366 --> 00:43:53.916 A:middle
Then you're done.

900
00:43:53.986 --> 00:43:55.616 A:middle
You can mark your
input as finished.

901
00:43:56.136 --> 00:44:00.686 A:middle
All right, let's say you're
going from a source media file.

902
00:44:00.686 --> 00:44:01.996 A:middle
That was in our second example.

903
00:44:02.486 --> 00:44:05.036 A:middle
So we have new APIs
for AVSReaderOutput.

904
00:44:05.696 --> 00:44:07.726 A:middle
You can prepare your
source for Multi-Pass

905
00:44:07.726 --> 00:44:10.246 A:middle
by saying supportsRandomAccess
equals yes.

906
00:44:10.816 --> 00:44:14.276 A:middle
Then when the encoder
wants new time ranges,

907
00:44:14.276 --> 00:44:16.296 A:middle
you need to reconfigure
your AVSReaderOutput

908
00:44:16.376 --> 00:44:17.676 A:middle
to deliver those time ranges.

909
00:44:18.126 --> 00:44:20.106 A:middle
So that's
resetForReadingTimeRanges

910
00:44:20.106 --> 00:44:21.696 A:middle
with an NSArray of time ranges.

911
00:44:23.056 --> 00:44:25.226 A:middle
Finally, when all
passes have completed you

912
00:44:25.226 --> 00:44:26.826 A:middle
callMarkConfigurationAsFinal.

913
00:44:27.256 --> 00:44:30.016 A:middle
This allows the AVSReaderOutput
to transition

914
00:44:30.016 --> 00:44:34.006 A:middle
to its completed state so it
can start tearing itself down.

915
00:44:34.036 --> 00:44:36.026 A:middle
Right. Now there's a couple
short cuts you can use

916
00:44:36.026 --> 00:44:38.696 A:middle
if you're using AVSReader
and AVSWriter

917
00:44:38.696 --> 00:44:39.796 A:middle
in combination together.

918
00:44:41.256 --> 00:44:44.076 A:middle
So you can enable
AVSReaderOutput

919
00:44:44.076 --> 00:44:46.766 A:middle
if the AVSWriterInput
supports Multi-Pass.

920
00:44:47.086 --> 00:44:49.086 A:middle
So if the encoder
supports Multi-Pass,

921
00:44:49.696 --> 00:44:51.836 A:middle
we need to support random
access on the source.

922
00:44:52.366 --> 00:44:56.776 A:middle
Then you can reconfigure your
source to deliver samples

923
00:44:56.776 --> 00:44:58.236 A:middle
for the AVSWriterInput.

924
00:44:58.496 --> 00:45:01.266 A:middle
So with your readerOutput
call resetForReadingTimeRanges

925
00:45:01.476 --> 00:45:03.276 A:middle
with the pass description's
time ranges.

926
00:45:03.746 --> 00:45:06.026 A:middle
Let's go over that
in the sample.

927
00:45:07.046 --> 00:45:09.266 A:middle
So instead of delivering
for an arbitrary source,

928
00:45:09.266 --> 00:45:11.706 A:middle
we now want to deliver for
our AVS at ReaderOuput.

929
00:45:11.706 --> 00:45:13.576 A:middle
So we call
resetForReadingTimeRanges

930
00:45:13.576 --> 00:45:16.206 A:middle
with the pass description
source time ranges.

931
00:45:20.976 --> 00:45:24.416 A:middle
Great. So that's the new API
and AVFoundation for Multi-Pass.

932
00:45:24.416 --> 00:45:26.196 A:middle
Let's talk next about
Video Toolbox.

933
00:45:27.146 --> 00:45:30.336 A:middle
So in Video Toolbox, our encoder
frame analysis data base,

934
00:45:30.836 --> 00:45:33.746 A:middle
we like to call this
our VTMultiPassStorage.

935
00:45:34.776 --> 00:45:37.266 A:middle
We also have additions
to VTCompressionSession,

936
00:45:37.266 --> 00:45:39.166 A:middle
which David introduced in
his portion of the talk,

937
00:45:39.776 --> 00:45:43.866 A:middle
and decompressed database, or
as we call it, the VTFrameSilo.

938
00:45:44.306 --> 00:45:46.576 A:middle
So let's go over
the architecture,

939
00:45:47.426 --> 00:45:50.176 A:middle
but this time replacing
the frame database

940
00:45:50.176 --> 00:45:51.406 A:middle
and the encoder database

941
00:45:51.406 --> 00:45:53.296 A:middle
with the objects
that we actually use.

942
00:45:54.066 --> 00:45:55.996 A:middle
So in this case, we
have our VTFrameSilo

943
00:45:55.996 --> 00:45:57.676 A:middle
and our VTMultiPassStorage.

944
00:45:59.766 --> 00:46:00.826 A:middle
We're done with this pass.

945
00:46:00.826 --> 00:46:02.596 A:middle
The encoder wants to
see samples again.

946
00:46:04.276 --> 00:46:06.606 A:middle
We're sending in those
samples that it requests.

947
00:46:09.556 --> 00:46:12.856 A:middle
Then we're finished and we can
tear down the VTMultiPassStorage

948
00:46:12.856 --> 00:46:19.006 A:middle
and the compression session and
we're left with our FrameSilo.

949
00:46:19.066 --> 00:46:20.646 A:middle
So this is where we
need to perform the copy

950
00:46:20.646 --> 00:46:22.566 A:middle
from the FrameSilo to
the output movie file.

951
00:46:23.096 --> 00:46:26.966 A:middle
Great, we have our
output movie file.

952
00:46:28.276 --> 00:46:31.476 A:middle
So first off, let's go over
what the VTMultiPassStorage is.

953
00:46:31.476 --> 00:46:33.256 A:middle
So this is the encoder analysis.

954
00:46:33.476 --> 00:46:35.276 A:middle
This is a pretty simple API.

955
00:46:35.416 --> 00:46:37.036 A:middle
First you create the storage

956
00:46:38.296 --> 00:46:40.606 A:middle
and then you close the
file once you're finished.

957
00:46:40.876 --> 00:46:43.996 A:middle
So that's all the API
that you need to use.

958
00:46:44.406 --> 00:46:46.566 A:middle
The data that's stored in
this is private to the encoder

959
00:46:46.566 --> 00:46:48.486 A:middle
and you don't have
to worry about it.

960
00:46:49.626 --> 00:46:52.256 A:middle
Next, let's talk about additions
to VTCompressionSession.

961
00:46:53.906 --> 00:46:56.336 A:middle
So first, you need to tell
the VTCompressionSession

962
00:46:56.336 --> 00:46:59.426 A:middle
and the encoder about
your VTMultiPassStorage.

963
00:46:59.546 --> 00:47:01.796 A:middle
So you can do that by
setting a property.

964
00:47:02.246 --> 00:47:04.386 A:middle
This will tell the
encoder to use MultiPass

965
00:47:04.386 --> 00:47:08.036 A:middle
and use this VTMultiPassStorage
for its frame analysis.

966
00:47:08.506 --> 00:47:12.706 A:middle
Next, we've added a couple
functions for MultiPass.

967
00:47:13.856 --> 00:47:18.506 A:middle
So you call begin pass before
you've appended any frames then

968
00:47:18.506 --> 00:47:19.946 A:middle
after you're done
appending frames

969
00:47:19.946 --> 00:47:21.776 A:middle
for that pass, you
call end pass.

970
00:47:22.456 --> 00:47:24.386 A:middle
End pass also asks the encoder

971
00:47:24.386 --> 00:47:25.796 A:middle
if another pass can
be performed.

972
00:47:27.816 --> 00:47:30.156 A:middle
So if another -- if the
encoder wants another pass

973
00:47:30.156 --> 00:47:32.446 A:middle
to be performed then you need
to ask it what time ranges

974
00:47:32.446 --> 00:47:34.156 A:middle
of samples it wants
for the next pass.

975
00:47:34.746 --> 00:47:37.006 A:middle
That's called
VTCompressionSession

976
00:47:37.006 --> 00:47:39.436 A:middle
GetTimeRangesFor NextPass
and you're given a count

977
00:47:39.436 --> 00:47:40.816 A:middle
and a C array of time ranges.

978
00:47:41.046 --> 00:47:44.776 A:middle
Now let's talk about
the VTFrameSilo.

979
00:47:44.776 --> 00:47:46.716 A:middle
So this is the compressed
frame store.

980
00:47:48.416 --> 00:47:52.776 A:middle
So like the other objects you
created, and then you want

981
00:47:52.776 --> 00:47:55.566 A:middle
to add samples to
this VTFrameSilo.

982
00:47:57.226 --> 00:47:59.796 A:middle
So frames will automatically
be replaced

983
00:47:59.796 --> 00:48:01.996 A:middle
if they have the same
presentation timestamp

984
00:48:01.996 --> 00:48:05.036 A:middle
and how this data is stored
is abstracted away from you

985
00:48:05.036 --> 00:48:06.446 A:middle
and you don't need
to worry about it.

986
00:48:06.446 --> 00:48:09.766 A:middle
It's a convenient
database for you to use.

987
00:48:09.886 --> 00:48:12.656 A:middle
Then you can prepare the
VTFrameSilo for the next pass.

988
00:48:12.736 --> 00:48:16.826 A:middle
This optimizes the
storage for the next pass.

989
00:48:19.756 --> 00:48:23.146 A:middle
Finally, let's talk about
the copy from the VTFrameSilo

990
00:48:23.286 --> 00:48:24.456 A:middle
to the output movie file.

991
00:48:25.766 --> 00:48:28.976 A:middle
So you can retrieve samples
for a given time range.

992
00:48:29.286 --> 00:48:32.086 A:middle
This allows you to get a
sample in a block callback

993
00:48:32.086 --> 00:48:34.496 A:middle
that you provide and add it
to your output movie file.

994
00:48:35.156 --> 00:48:38.166 A:middle
Right, that's the new
Video Toolbox APIs.

995
00:48:38.356 --> 00:48:40.456 A:middle
So I want to close with
a couple considerations.

996
00:48:41.756 --> 00:48:44.256 A:middle
So we've talked about
how MultiPass works

997
00:48:44.256 --> 00:48:47.546 A:middle
and what APIs you can use in
AVFoundation and Video Toolbox,

998
00:48:47.826 --> 00:48:49.556 A:middle
but we need to talk
about your use cases

999
00:48:49.556 --> 00:48:51.976 A:middle
and your priority in your app.

1000
00:48:52.226 --> 00:48:54.236 A:middle
So if you're performing
real time encoding,

1001
00:48:55.396 --> 00:48:56.856 A:middle
you should be using Single-Pass.

1002
00:48:57.066 --> 00:48:59.256 A:middle
Real time encoding has
very specific deadlines

1003
00:48:59.256 --> 00:49:01.046 A:middle
of how much compression can take

1004
00:49:01.456 --> 00:49:04.486 A:middle
and Multi-Pass will perform
more passes over the time range,

1005
00:49:04.516 --> 00:49:06.176 A:middle
so use Single-Pass
in these cases.

1006
00:49:08.996 --> 00:49:11.416 A:middle
If you're concerned about
using the minimum amount

1007
00:49:11.416 --> 00:49:14.696 A:middle
of power during encoding,
use Single-Pass.

1008
00:49:15.076 --> 00:49:17.286 A:middle
Multiple passes will
take more power

1009
00:49:17.286 --> 00:49:19.406 A:middle
and as will the encoder
analysis.

1010
00:49:20.756 --> 00:49:23.186 A:middle
If you're concerned with
using the minimum amount

1011
00:49:23.186 --> 00:49:25.046 A:middle
of temporary storage
during the encode

1012
00:49:25.046 --> 00:49:28.466 A:middle
or transcode operation,
use Single-Pass.

1013
00:49:28.636 --> 00:49:30.046 A:middle
The encoder analysis storage

1014
00:49:30.046 --> 00:49:32.126 A:middle
and the frame database
will use more storage

1015
00:49:32.126 --> 00:49:33.206 A:middle
than the output medial file.

1016
00:49:34.856 --> 00:49:37.906 A:middle
However, if you're concerned
about having the best quality

1017
00:49:37.906 --> 00:49:40.876 A:middle
for your content,
Multi-Pass is a great option.

1018
00:49:41.496 --> 00:49:45.386 A:middle
If you want to be as close to
the target bit rate you set

1019
00:49:45.386 --> 00:49:47.566 A:middle
on the VTCompressionSession
or AssetWriter

1020
00:49:47.566 --> 00:49:50.346 A:middle
as possible, use Multi-Pass.

1021
00:49:50.346 --> 00:49:54.176 A:middle
Multi-Pass can see all of the
portions of your source media

1022
00:49:54.176 --> 00:49:56.496 A:middle
and so it can allocate bits
only where it needs to.

1023
00:49:56.596 --> 00:49:57.926 A:middle
It's very smart in this sense.

