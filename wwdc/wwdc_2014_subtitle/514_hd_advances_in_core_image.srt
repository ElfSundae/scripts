

1
00:00:12.046 --> 00:00:13.986 A:middle
&gt;&gt; My name is David Hayward
and welcome to our first

2
00:00:13.986 --> 00:00:16.206 A:middle
of two discussions
about Core Image.

3
00:00:16.206 --> 00:00:18.036 A:middle
And we'll be talking
today about what's new

4
00:00:18.036 --> 00:00:23.356 A:middle
in Core Image on
both iOS and OS X.

5
00:00:23.356 --> 00:00:24.736 A:middle
So what is Core Image?

6
00:00:25.126 --> 00:00:28.626 A:middle
Core Image is a fast,
easy, flexible framework

7
00:00:28.626 --> 00:00:29.946 A:middle
for doing image processing.

8
00:00:30.466 --> 00:00:31.726 A:middle
And it supports all

9
00:00:31.726 --> 00:00:35.476 A:middle
of our supported devices
on both iOS and OS X.

10
00:00:35.886 --> 00:00:39.996 A:middle
It's also used by several of our
key applications such as photos

11
00:00:40.966 --> 00:00:42.906 A:middle
on both platforms
and it allows you

12
00:00:42.906 --> 00:00:44.736 A:middle
to get very good
performance results

13
00:00:44.736 --> 00:00:46.466 A:middle
and very flexible output.

14
00:00:46.956 --> 00:00:49.906 A:middle
For those of you who may
be new to Core Image,

15
00:00:49.966 --> 00:00:51.856 A:middle
I just want to take a few
slides to talk about some

16
00:00:51.856 --> 00:00:53.786 A:middle
of the key concepts because
those will be relevant

17
00:00:53.786 --> 00:00:55.216 A:middle
for the rest of the
discussion today.

18
00:00:56.766 --> 00:00:59.736 A:middle
So first off, filters --
Core Image filters allow you

19
00:00:59.736 --> 00:01:03.036 A:middle
to perform per-pixel
operations on an image.

20
00:01:03.516 --> 00:01:06.736 A:middle
In a simple example, you have
an original image and you want

21
00:01:06.736 --> 00:01:08.726 A:middle
to apply a sepia
tone filter to it.

22
00:01:09.056 --> 00:01:10.326 A:middle
And you'll get a
resulting image.

23
00:01:11.026 --> 00:01:13.196 A:middle
Obviously, that's fun
but where things start

24
00:01:13.196 --> 00:01:15.756 A:middle
to get interesting is where
you combine multiple filters

25
00:01:15.756 --> 00:01:18.586 A:middle
in either chains
or complex graphs.

26
00:01:18.666 --> 00:01:21.676 A:middle
And here an example, you can see
a very interesting result you

27
00:01:21.676 --> 00:01:24.166 A:middle
can get by just chaining
three filters together,

28
00:01:24.226 --> 00:01:26.846 A:middle
sepia tone plus a hue
rotation to turn it

29
00:01:26.846 --> 00:01:29.556 A:middle
into a blue tone
image plus a contrast

30
00:01:29.556 --> 00:01:30.886 A:middle
to make it more dramatic.

31
00:01:32.316 --> 00:01:35.246 A:middle
One thing to keep in mind is
these intermediate images are

32
00:01:35.246 --> 00:01:36.606 A:middle
actually lightweight objects.

33
00:01:36.936 --> 00:01:39.396 A:middle
So there need not necessarily
even be memory associated

34
00:01:39.396 --> 00:01:41.816 A:middle
with these of any
significant amount.

35
00:01:43.216 --> 00:01:44.476 A:middle
Another thing that's
important to keep

36
00:01:44.476 --> 00:01:49.086 A:middle
in mind is each filter may have
one or more kernels associated.

37
00:01:49.086 --> 00:01:51.626 A:middle
So these kernels are
the actual algorithm

38
00:01:51.626 --> 00:01:53.606 A:middle
that implements each
filter's effect.

39
00:01:54.676 --> 00:01:55.616 A:middle
And one of the great things

40
00:01:55.616 --> 00:01:58.436 A:middle
about Core Image is we
can take these kernels

41
00:01:58.706 --> 00:02:01.656 A:middle
and concatenate them into
programs and this allows us

42
00:02:01.656 --> 00:02:04.896 A:middle
at runtime to minimize the
amount of intermediate results

43
00:02:04.996 --> 00:02:07.516 A:middle
and with some great
compiler technology,

44
00:02:07.906 --> 00:02:11.406 A:middle
both at the image processing and
at the low-level compiler level,

45
00:02:11.576 --> 00:02:13.616 A:middle
we're able to get the
best possible performance

46
00:02:13.746 --> 00:02:14.996 A:middle
out of a complex graph.

47
00:02:15.496 --> 00:02:18.586 A:middle
So that's the basics in
terms of how it works.

48
00:02:18.886 --> 00:02:21.136 A:middle
These are the four key
object types that you need

49
00:02:21.136 --> 00:02:23.116 A:middle
to be familiar with if you
want to use Core Image.

50
00:02:23.696 --> 00:02:26.286 A:middle
The first which we'll be talking
about a lot today is CIKernel.

51
00:02:26.836 --> 00:02:28.956 A:middle
And this represents a
program that's written in CI's

52
00:02:28.956 --> 00:02:30.936 A:middle
or Core Image's Kernel language.

53
00:02:31.876 --> 00:02:36.056 A:middle
Second object type is a
CIFilter and this is an object

54
00:02:36.056 --> 00:02:38.536 A:middle
that has mutable
input parameters

55
00:02:38.536 --> 00:02:40.956 A:middle
and those parameters
can be images or numbers

56
00:02:40.956 --> 00:02:42.846 A:middle
or vectors or other types.

57
00:02:43.016 --> 00:02:46.166 A:middle
And it also allows you to
use one or more kernels

58
00:02:46.456 --> 00:02:49.286 A:middle
to create a new image based on
the current state of the output

59
00:02:49.286 --> 00:02:51.156 A:middle
or of the input parameters.

60
00:02:52.826 --> 00:02:56.556 A:middle
Third key type is a CIImage
and this is an immutable object

61
00:02:56.556 --> 00:02:59.416 A:middle
that represents the
recipe to produce an image.

62
00:03:00.036 --> 00:03:03.246 A:middle
Just the act of creating an
image does not necessarily do

63
00:03:03.246 --> 00:03:03.966 A:middle
any real work.

64
00:03:04.226 --> 00:03:06.596 A:middle
The actual work occurs
when you render a CIImage

65
00:03:06.596 --> 00:03:08.896 A:middle
into a CIContext and
that's the object

66
00:03:08.896 --> 00:03:10.316 A:middle
through which you
render results.

67
00:03:11.296 --> 00:03:12.896 A:middle
So those are the basics.

68
00:03:13.476 --> 00:03:15.476 A:middle
What I want to talk
about today is what's new

69
00:03:15.476 --> 00:03:17.656 A:middle
in Core Image this year and
we have a lot to talk about.

70
00:03:18.096 --> 00:03:20.276 A:middle
We have a bunch of new
things that are on iOS.

71
00:03:20.386 --> 00:03:23.276 A:middle
For example, we have our
most requested feature

72
00:03:23.386 --> 00:03:24.886 A:middle
which is Custom CIKernels.

73
00:03:25.456 --> 00:03:28.236 A:middle
We also like to talk about
how you can do Photo Editing

74
00:03:28.236 --> 00:03:29.546 A:middle
Extensions using Core Image

75
00:03:29.936 --> 00:03:33.226 A:middle
and also how we can now
support large images on iOS.

76
00:03:33.386 --> 00:03:36.696 A:middle
We also made some improvements
to how the GPU render is used.

77
00:03:38.086 --> 00:03:40.026 A:middle
We also have some
API modernization.

78
00:03:40.566 --> 00:03:42.166 A:middle
We have some new
built-in filters.

79
00:03:42.506 --> 00:03:45.406 A:middle
We have some new CIDetectors
and then lastly, we will talk

80
00:03:45.406 --> 00:03:50.006 A:middle
about some new things that
we have on the Mac OS X side,

81
00:03:50.356 --> 00:03:52.946 A:middle
improve RAW support and
how to use a second GPU.

82
00:03:54.716 --> 00:03:56.926 A:middle
So first and most interesting,

83
00:03:56.926 --> 00:03:59.236 A:middle
I think is Custom
CIKernels on iOS.

84
00:03:59.236 --> 00:04:01.466 A:middle
As I mentioned, this has been
our top requested feature.

85
00:04:02.146 --> 00:04:06.146 A:middle
Core Image already has 115
great built-in filters on iOS.

86
00:04:06.536 --> 00:04:08.346 A:middle
But now you can easily
create your own.

87
00:04:08.686 --> 00:04:11.246 A:middle
So this is a terrific
feature for developers.

88
00:04:12.076 --> 00:04:14.656 A:middle
When you're writing
CIKernels on iOS,

89
00:04:14.656 --> 00:04:16.346 A:middle
you can use the same
CIKernel language

90
00:04:16.346 --> 00:04:18.336 A:middle
that you use today on OS X.

91
00:04:18.926 --> 00:04:20.185 A:middle
There are a few extensions

92
00:04:20.245 --> 00:04:23.526 A:middle
which allow making
typical kernels even easier

93
00:04:23.706 --> 00:04:25.486 A:middle
and we'll talk about
that in much more detail

94
00:04:25.486 --> 00:04:26.596 A:middle
in our next presentation.

95
00:04:27.856 --> 00:04:30.076 A:middle
Where can your CIKernels live?

96
00:04:30.456 --> 00:04:32.056 A:middle
Well, they can live
in your application.

97
00:04:32.386 --> 00:04:35.016 A:middle
The kernel code can
either be a text resource

98
00:04:35.116 --> 00:04:36.966 A:middle
or it can just be an
NSString, if you'd like.

99
00:04:37.476 --> 00:04:41.356 A:middle
The kernel is wrapped
up in CIFilter subclass

100
00:04:41.356 --> 00:04:43.496 A:middle
that you provide that
applies to kernels

101
00:04:43.496 --> 00:04:44.636 A:middle
to produce an output image.

102
00:04:45.996 --> 00:04:48.246 A:middle
Another great place for
your Custom CIKernels

103
00:04:48.246 --> 00:04:50.426 A:middle
to go is inside an
App Extension.

104
00:04:50.426 --> 00:04:53.986 A:middle
For example, Photo Editing
Extensions can use CIKernels

105
00:04:53.986 --> 00:04:56.116 A:middle
and CIFilter subclasses
very effectively.

106
00:04:56.636 --> 00:05:00.486 A:middle
And you can use them to modify
either photos or videos.

107
00:05:02.736 --> 00:05:05.396 A:middle
So again, we'll be talking
our next presentation

108
00:05:05.576 --> 00:05:09.376 A:middle
in much more detail about
how to use CIKernels on iOS

109
00:05:09.406 --> 00:05:11.076 A:middle
but let me just give
you a little teaser now

110
00:05:11.176 --> 00:05:12.276 A:middle
of how simple it is.

111
00:05:12.766 --> 00:05:14.836 A:middle
Here we have in just
basically two lines of code,

112
00:05:15.316 --> 00:05:17.216 A:middle
how to use a Custom CIKernel.

113
00:05:17.606 --> 00:05:22.036 A:middle
We create an NSString which has
some CI Core Image source code

114
00:05:22.036 --> 00:05:22.276 A:middle
in it.

115
00:05:22.646 --> 00:05:24.766 A:middle
This is a very simple kernel

116
00:05:24.766 --> 00:05:27.546 A:middle
that takes a pixel
value and inverts it.

117
00:05:27.896 --> 00:05:30.486 A:middle
You'll notice it's actually
subtracting it not from 1

118
00:05:30.486 --> 00:05:31.576 A:middle
but from the alpha value.

119
00:05:31.576 --> 00:05:34.746 A:middle
That's the correct way to invert
if you've got premultiplied data

120
00:05:34.856 --> 00:05:36.766 A:middle
which is what Core
Image receives.

121
00:05:37.766 --> 00:05:40.166 A:middle
Once you have the program
written then all you need

122
00:05:40.166 --> 00:05:42.716 A:middle
to do is create a
CIKernel object

123
00:05:42.716 --> 00:05:45.416 A:middle
from the string and
then apply it.

124
00:05:45.776 --> 00:05:47.456 A:middle
You can specify two things.

125
00:05:47.456 --> 00:05:51.366 A:middle
One is the resulting
extent of the produced image

126
00:05:51.786 --> 00:05:55.816 A:middle
and also the arguments that
will be passed to that kernel.

127
00:05:56.286 --> 00:05:58.836 A:middle
In this particular example,
there is only a single argument

128
00:05:58.836 --> 00:06:02.196 A:middle
which is the input image and
so as a result, our arguments

129
00:06:02.336 --> 00:06:06.686 A:middle
down below is just an array
with a single image in it.

130
00:06:07.636 --> 00:06:10.636 A:middle
So to give you a little bit
of idea of what that looks

131
00:06:10.636 --> 00:06:12.156 A:middle
like in practice, I
have a quick demo.

132
00:06:12.546 --> 00:06:14.556 A:middle
This is a fun example
that we wrote.

133
00:06:15.496 --> 00:06:18.016 A:middle
And it's kind of an
example of something

134
00:06:18.016 --> 00:06:20.776 A:middle
that you wouldn't necessarily
have as a built-in filter.

135
00:06:22.296 --> 00:06:22.716 A:middle
Let's see.

136
00:06:23.846 --> 00:06:27.216 A:middle
But it would be fun for
a presentation like this.

137
00:06:27.296 --> 00:06:30.016 A:middle
So we have an application
called Core Image Funhouse

138
00:06:30.596 --> 00:06:33.656 A:middle
and this allows you to explore
all the built-in filters

139
00:06:33.936 --> 00:06:37.276 A:middle
and also allows you to see
some sample code for how

140
00:06:37.416 --> 00:06:38.676 A:middle
to write Custom CIKernels.

141
00:06:39.226 --> 00:06:40.786 A:middle
So the image starts out as gray.

142
00:06:41.346 --> 00:06:44.116 A:middle
The first thing we need to do is
provide an image to start with.

143
00:06:44.376 --> 00:06:46.936 A:middle
And we're going to say that we
want the video feed to come in.

144
00:06:47.456 --> 00:06:51.146 A:middle
And then I'm going to add
a filter and you can see,

145
00:06:51.146 --> 00:06:53.056 A:middle
we're seeing a list
of all the filters

146
00:06:53.056 --> 00:06:54.556 A:middle
that are part of Core Image.

147
00:06:55.066 --> 00:06:58.416 A:middle
And we created one down
here called WWDC 2014

148
00:06:59.056 --> 00:07:01.366 A:middle
and I hope you can see this
so that I can kind of wave

149
00:07:01.366 --> 00:07:03.316 A:middle
in front of the camera.

150
00:07:03.316 --> 00:07:07.706 A:middle
What we're doing here is
actually algorithmically taking

151
00:07:07.706 --> 00:07:10.426 A:middle
the luminance from the
video feed and then using

152
00:07:10.426 --> 00:07:11.736 A:middle
that to control the size

153
00:07:11.736 --> 00:07:15.856 A:middle
of the geometrically
generated rounded rectangle.

154
00:07:16.376 --> 00:07:20.676 A:middle
And we can change the size
of that larger or smaller

155
00:07:21.776 --> 00:07:24.446 A:middle
or we can change the amount
of the rounded radius here.

156
00:07:24.846 --> 00:07:28.686 A:middle
It's actually a little easier
to see that it's a video feed

157
00:07:28.686 --> 00:07:34.076 A:middle
when it's smaller but it looks
more cool when it's bigger.

158
00:07:34.206 --> 00:07:38.086 A:middle
So and we're getting about
30 frames per second on that

159
00:07:38.086 --> 00:07:40.816 A:middle
which is probably the frame
rate of the camera right now.

160
00:07:41.406 --> 00:07:44.956 A:middle
So that's our short example and
we'll have that code available

161
00:07:45.236 --> 00:07:46.426 A:middle
for download at some point soon.

162
00:07:47.646 --> 00:07:50.326 A:middle
So again, that's Custom
CIKernels and please come

163
00:07:50.326 --> 00:07:53.366 A:middle
to our second session to see
all you can learn about that.

164
00:07:54.296 --> 00:07:55.516 A:middle
The next thing I'd like to talk

165
00:07:55.516 --> 00:07:59.176 A:middle
about briefly is the Photo
Editing Extensions on iOS.

166
00:07:59.236 --> 00:08:02.206 A:middle
There are whole talks on
that this year at WWDC.

167
00:08:02.446 --> 00:08:05.256 A:middle
I'd like to talk a little
bit about how that works

168
00:08:05.346 --> 00:08:06.706 A:middle
in relationship to Core Image.

169
00:08:07.326 --> 00:08:08.956 A:middle
So here's just a
little short video run

170
00:08:08.956 --> 00:08:11.156 A:middle
through of how this
works in practice.

171
00:08:11.946 --> 00:08:14.586 A:middle
What we have is an image
the user wanted to edit.

172
00:08:14.876 --> 00:08:16.996 A:middle
They brought up a
list of extensions.

173
00:08:16.996 --> 00:08:18.186 A:middle
We picked the Core Image one

174
00:08:18.966 --> 00:08:22.196 A:middle
and this particular Core Image
based extension has two sliders.

175
00:08:22.196 --> 00:08:25.396 A:middle
One is the amount of sepia
tone which we can slide

176
00:08:25.806 --> 00:08:27.526 A:middle
and we're getting
very good frame rates

177
00:08:27.526 --> 00:08:29.516 A:middle
to the screen as we do this.

178
00:08:30.046 --> 00:08:33.866 A:middle
And then the second slider
is a vignette amount.

179
00:08:34.126 --> 00:08:36.056 A:middle
So it starts out with
a large radius and then

180
00:08:36.056 --> 00:08:38.066 A:middle
as you bring the radius
smaller, you get more

181
00:08:38.306 --> 00:08:41.926 A:middle
of the vignette effect
as you bring it down.

182
00:08:42.116 --> 00:08:44.246 A:middle
And all of this is
happening right now

183
00:08:44.246 --> 00:08:45.596 A:middle
on a display-sized image.

184
00:08:45.916 --> 00:08:48.236 A:middle
Later on, when you
hit Save, it's applied

185
00:08:48.236 --> 00:08:51.206 A:middle
on a full-sized image which
is the 12 megapixel image

186
00:08:51.206 --> 00:08:51.736 A:middle
in this case.

187
00:08:52.266 --> 00:08:54.276 A:middle
And it goes back into your
library with your edits.

188
00:08:54.956 --> 00:08:56.436 A:middle
So that's how it
looks in practice.

189
00:08:56.746 --> 00:08:59.206 A:middle
I'm not going to go into too
much detail on how to code this

190
00:08:59.276 --> 00:09:01.166 A:middle
but I'll give you
some good advice here.

191
00:09:01.796 --> 00:09:05.106 A:middle
First off, you can start to
create a Photo Editing Extension

192
00:09:05.106 --> 00:09:06.916 A:middle
by going into the
templates in Xcode.

193
00:09:07.516 --> 00:09:09.956 A:middle
We'll also provide some
sample code as well

194
00:09:09.956 --> 00:09:11.216 A:middle
so that'll be a good
starting point.

195
00:09:11.766 --> 00:09:13.316 A:middle
But as I said, I
wanted to talk a bit

196
00:09:13.316 --> 00:09:15.426 A:middle
about how you can use
Core Image effectively

197
00:09:15.726 --> 00:09:17.366 A:middle
within Photo Editing Extensions.

198
00:09:18.316 --> 00:09:20.106 A:middle
There's basically three steps.

199
00:09:20.196 --> 00:09:22.916 A:middle
The first step is when your
extension is initialized,

200
00:09:23.446 --> 00:09:26.486 A:middle
what you want to do is you want
to ask the editing input object

201
00:09:26.486 --> 00:09:28.466 A:middle
for a display-sized image.

202
00:09:29.046 --> 00:09:31.256 A:middle
Initially, that is a UI
image object and from

203
00:09:31.256 --> 00:09:34.446 A:middle
that you can create a CGImage
and then from that CIImage.

204
00:09:34.446 --> 00:09:36.496 A:middle
That sounds like
a couple of steps

205
00:09:36.496 --> 00:09:39.226 A:middle
but it's actually those are
just lightweight wrappers.

206
00:09:39.896 --> 00:09:41.876 A:middle
Once you've created that
CIImage, we're going to store

207
00:09:41.876 --> 00:09:44.516 A:middle
that in a property
for our delegate.

208
00:09:45.206 --> 00:09:47.756 A:middle
The other thing, it's a good
time to do at that time is

209
00:09:47.756 --> 00:09:49.756 A:middle
to create your view that you're
going to be rendering into.

210
00:09:49.756 --> 00:09:53.736 A:middle
We recommend using a GLKView
and also create a CIContext

211
00:09:53.736 --> 00:09:56.116 A:middle
that is associated
with that view.

212
00:09:56.116 --> 00:09:58.466 A:middle
And it's good to store that
away in the property as well.

213
00:10:00.326 --> 00:10:04.516 A:middle
Step two is what you do every
time the user makes an edit

214
00:10:04.516 --> 00:10:07.316 A:middle
in your extension so every
time the slider moves.

215
00:10:07.866 --> 00:10:09.136 A:middle
And this is very simple.

216
00:10:09.236 --> 00:10:12.166 A:middle
What you do is you recall
the display-sized CIImage

217
00:10:12.166 --> 00:10:13.386 A:middle
that we created in step one.

218
00:10:14.146 --> 00:10:16.096 A:middle
We apply the filters
that correspond

219
00:10:16.096 --> 00:10:17.836 A:middle
to those slider adjustments.

220
00:10:17.886 --> 00:10:21.696 A:middle
So in that previous example,
it was the sepia tone filter

221
00:10:21.696 --> 00:10:23.276 A:middle
and the vignette effect filter.

222
00:10:24.076 --> 00:10:25.416 A:middle
And then once you've
chained those together,

223
00:10:25.416 --> 00:10:26.856 A:middle
you get the output
image from that.

224
00:10:27.466 --> 00:10:29.876 A:middle
And then you're going to
draw that using the CIContext

225
00:10:29.876 --> 00:10:31.776 A:middle
that we also created
in step one.

226
00:10:32.326 --> 00:10:34.566 A:middle
And Step three is what happens

227
00:10:34.566 --> 00:10:36.086 A:middle
when the user clicks
the Done button.

228
00:10:36.086 --> 00:10:38.826 A:middle
And this is slightly
different because in this case,

229
00:10:38.826 --> 00:10:40.956 A:middle
you want to apply the effect
on the full-sized image.

230
00:10:41.516 --> 00:10:44.826 A:middle
So what we have here is we can
ask the editing input object

231
00:10:44.826 --> 00:10:46.676 A:middle
for its fullSizeImageURL.

232
00:10:46.876 --> 00:10:48.836 A:middle
From that, we create a CIImage

233
00:10:49.376 --> 00:10:51.196 A:middle
and we apply the
filters to this as well.

234
00:10:51.606 --> 00:10:54.386 A:middle
Now, for the most part, this is
the same as we did in step two.

235
00:10:54.676 --> 00:10:57.696 A:middle
Some parameters however such as
radiuses may need to be scaled

236
00:10:58.176 --> 00:11:00.116 A:middle
in accordance to the fact
that you're now working

237
00:11:00.116 --> 00:11:01.076 A:middle
on a full-sized image.

238
00:11:02.106 --> 00:11:04.266 A:middle
Once you have chained
together your filters,

239
00:11:04.266 --> 00:11:06.486 A:middle
you ask the output
image and then you --

240
00:11:06.936 --> 00:11:10.526 A:middle
the way this API works is you
return the CGImage so you can do

241
00:11:10.526 --> 00:11:11.926 A:middle
that very easily
with Core Image.

242
00:11:12.286 --> 00:11:16.606 A:middle
You ask a CIContext to create a
CGImage and this will work even

243
00:11:16.606 --> 00:11:18.166 A:middle
on the full-sized image.

244
00:11:19.876 --> 00:11:22.446 A:middle
So that brings me to the
next subject I want to talk

245
00:11:22.446 --> 00:11:25.426 A:middle
about today which is working
on large images on iOS.

246
00:11:25.556 --> 00:11:28.646 A:middle
So we've made some great
improvements here in addition

247
00:11:28.646 --> 00:11:31.436 A:middle
to the supporting kernels, this
is I think our second key thing

248
00:11:31.436 --> 00:11:33.026 A:middle
that we've added
this year on iOS.

249
00:11:34.456 --> 00:11:38.116 A:middle
So now you can -- we have
full support for images

250
00:11:38.116 --> 00:11:40.096 A:middle
that are larger than
the GPU texture limits.

251
00:11:40.716 --> 00:11:43.716 A:middle
And this means that input
images can now be larger than 4K

252
00:11:44.186 --> 00:11:46.966 A:middle
and output renders
can be larger than 4K.

253
00:11:47.436 --> 00:11:50.336 A:middle
We refer to this as large
images but in practice,

254
00:11:50.386 --> 00:11:52.506 A:middle
4K images are not
that large these days.

255
00:11:52.506 --> 00:11:56.076 A:middle
Many of our devices'
cameras are bigger than that.

256
00:11:56.466 --> 00:11:58.256 A:middle
So this is actually a
really critical feature

257
00:11:58.256 --> 00:11:59.916 A:middle
to support this size
image as well.

258
00:12:00.956 --> 00:12:03.516 A:middle
The way we achieve
this automatically is

259
00:12:03.516 --> 00:12:05.656 A:middle
that we have automatic
tiling support in Core Image.

260
00:12:06.196 --> 00:12:08.486 A:middle
And this among other
things leverages some great

261
00:12:08.486 --> 00:12:11.496 A:middle
improvements that were made
in ImageIO and they're JPEG

262
00:12:11.496 --> 00:12:14.096 A:middle
to improve how the
decoder and encoder works.

263
00:12:14.876 --> 00:12:17.056 A:middle
And also, there's
some great features

264
00:12:17.056 --> 00:12:20.346 A:middle
in the Core Image language
that allows supporting

265
00:12:20.346 --> 00:12:21.416 A:middle
of large image as well.

266
00:12:22.176 --> 00:12:24.516 A:middle
So let me talk about that last
item in a little bit of detail.

267
00:12:25.276 --> 00:12:28.006 A:middle
So the CIKernel language
allows your kernels

268
00:12:28.006 --> 00:12:30.016 A:middle
to just work automatically
regardless

269
00:12:30.016 --> 00:12:33.416 A:middle
of whether tiling happens
or at what size it happens.

270
00:12:33.846 --> 00:12:34.876 A:middle
So this is a great feature

271
00:12:34.876 --> 00:12:38.226 A:middle
that makes writing
CIKernels very flexible.

272
00:12:39.306 --> 00:12:43.286 A:middle
The way this is achieved is by
two key extensions that we have

273
00:12:43.286 --> 00:12:45.086 A:middle
in our language and
these are available both

274
00:12:45.086 --> 00:12:47.466 A:middle
on OS X and on iOS now.

275
00:12:48.096 --> 00:12:50.886 A:middle
The first is a function called
desk coordinate or deskCoord

276
00:12:51.566 --> 00:12:53.216 A:middle
and that allows Core Image

277
00:12:53.516 --> 00:12:55.486 A:middle
to support tiled
output automatically.

278
00:12:56.286 --> 00:12:59.176 A:middle
It basically allows your kernel
to see the desk coordinate

279
00:12:59.456 --> 00:13:02.136 A:middle
in the native images space even
though we may only be rendering

280
00:13:02.136 --> 00:13:03.866 A:middle
a given tile at a time.

281
00:13:05.026 --> 00:13:08.656 A:middle
Similarly, there's a function
called samplerTransform

282
00:13:08.956 --> 00:13:11.356 A:middle
and that allows Core
Image to support tiling

283
00:13:11.356 --> 00:13:13.776 A:middle
of large input images
automatically.

284
00:13:14.456 --> 00:13:17.616 A:middle
So this is the two key things
about the CIKernel language

285
00:13:17.616 --> 00:13:20.186 A:middle
that we'll talk about
in much more detail

286
00:13:20.186 --> 00:13:21.246 A:middle
in our second presentation.

287
00:13:23.736 --> 00:13:27.466 A:middle
So another great thing about our
large image support is how we

288
00:13:27.466 --> 00:13:30.486 A:middle
work together with CGImageRef

289
00:13:30.556 --> 00:13:32.686 A:middle
and how we get some
great improvements

290
00:13:32.686 --> 00:13:35.106 A:middle
on iOS 8 by being lazy.

291
00:13:36.066 --> 00:13:37.656 A:middle
So one thing to keep in mind is

292
00:13:37.656 --> 00:13:39.686 A:middle
if you have a small
input CGImage

293
00:13:39.716 --> 00:13:44.096 A:middle
that you create a CIImage from,
then this image is fully decoded

294
00:13:44.096 --> 00:13:46.926 A:middle
at the time you call
CIImage initWith CGImage.

295
00:13:48.026 --> 00:13:50.356 A:middle
And that's actually usually
the right thing to do

296
00:13:50.356 --> 00:13:53.176 A:middle
for small images
because you may be using

297
00:13:53.176 --> 00:13:55.076 A:middle
that image multiple
times and you want

298
00:13:55.076 --> 00:14:00.896 A:middle
to take the performance impact
of decoding the JPEG once early.

299
00:14:01.976 --> 00:14:05.156 A:middle
However, for large images,
that's not a good strategy

300
00:14:05.246 --> 00:14:08.106 A:middle
because you don't want to
require all of that memory

301
00:14:08.656 --> 00:14:10.496 A:middle
to be -- for that JPEG

302
00:14:10.496 --> 00:14:12.346 A:middle
to be compressed unless
you know you need it.

303
00:14:13.156 --> 00:14:17.566 A:middle
So if you have a large
input CGImage, that image,

304
00:14:18.026 --> 00:14:21.516 A:middle
that JPEG image behind that
CGImage is decoded only

305
00:14:21.516 --> 00:14:24.596 A:middle
as needed when you
call CIContext render.

306
00:14:25.186 --> 00:14:29.966 A:middle
So that's a very
important detail.

307
00:14:30.216 --> 00:14:33.466 A:middle
Similarly, when you're
producing a CGImage as an output

308
00:14:33.466 --> 00:14:38.556 A:middle
of CIImage, when you call
CIContext createCGImage,

309
00:14:38.556 --> 00:14:42.706 A:middle
if the output CGImage is small,
then the image is fully rendered

310
00:14:42.706 --> 00:14:43.956 A:middle
when CGImage is called.

311
00:14:44.746 --> 00:14:47.856 A:middle
However, if you're producing
a large CGImage as an output

312
00:14:48.286 --> 00:14:51.376 A:middle
such as an example of
the photo extensions,

313
00:14:51.816 --> 00:14:54.536 A:middle
the image is only
rendered as needed

314
00:14:54.536 --> 00:14:56.166 A:middle
when the CGImage is rendered.

315
00:14:57.286 --> 00:15:00.596 A:middle
This is also important because
a very common situation is you

316
00:15:00.596 --> 00:15:04.106 A:middle
pass the CGImage, the
CGImage DestinationFinalize

317
00:15:04.356 --> 00:15:08.106 A:middle
to encode it back as a JPEG.

318
00:15:08.316 --> 00:15:12.406 A:middle
So what all this means is that
if you have a very large JPEG,

319
00:15:12.856 --> 00:15:16.706 A:middle
you can take that large JPEG,
decode it, apply a filter to it

320
00:15:16.856 --> 00:15:20.196 A:middle
and re-encode it back into
a JPEG with minimal memory

321
00:15:20.596 --> 00:15:22.786 A:middle
and great performance
and this is a huge win

322
00:15:23.146 --> 00:15:24.496 A:middle
for Core Image on iOS.

323
00:15:25.036 --> 00:15:26.316 A:middle
So let's take a quick example.

324
00:15:26.636 --> 00:15:31.016 A:middle
You're applying a sepia tone
effect to a 4K by 6K JPEG,

325
00:15:31.886 --> 00:15:33.726 A:middle
so 100 megabytes of image.

326
00:15:33.896 --> 00:15:38.606 A:middle
That on iOS 7 took 17 seconds
to decode, apply the filter

327
00:15:38.606 --> 00:15:39.876 A:middle
and re-encode it as a JPEG.

328
00:15:40.666 --> 00:15:42.316 A:middle
On iOS 8, that's 1 second.

329
00:15:43.516 --> 00:15:46.756 A:middle
[ Applause ]

330
00:15:47.256 --> 00:15:50.316 A:middle
And just as important on iOS
is the memory high water mark

331
00:15:50.396 --> 00:15:52.786 A:middle
because that can really
force your application

332
00:15:52.786 --> 00:15:54.366 A:middle
into an unhappy place.

333
00:15:54.506 --> 00:15:58.016 A:middle
And our high water mark
on iOS 7 was 200 megabytes

334
00:15:58.016 --> 00:15:58.736 A:middle
which makes sense.

335
00:15:58.736 --> 00:16:01.696 A:middle
We have a source image that was
fully decompressed and we need

336
00:16:01.696 --> 00:16:03.956 A:middle
to produce a whole new image
which is the same size.

337
00:16:04.836 --> 00:16:06.286 A:middle
However because we
now have tiling,

338
00:16:06.286 --> 00:16:09.576 A:middle
our high water mark
is now 25 megabytes.

339
00:16:10.516 --> 00:16:15.026 A:middle
[ Applause ]

340
00:16:15.526 --> 00:16:19.456 A:middle
And just to summarize, on iOS
7, we worked on the full image

341
00:16:19.456 --> 00:16:21.786 A:middle
at a time and because it
was large, we often had

342
00:16:21.786 --> 00:16:22.916 A:middle
to use a CPU renderer.

343
00:16:23.566 --> 00:16:27.286 A:middle
On iOS 8, we have automatic
tiling and as a result,

344
00:16:27.286 --> 00:16:29.856 A:middle
we can use the GPU
which is a huge win.

345
00:16:31.516 --> 00:16:34.436 A:middle
So we've also made
some other improvements

346
00:16:34.436 --> 00:16:36.386 A:middle
to how GPU rendering
works with Core Image

347
00:16:36.386 --> 00:16:38.666 A:middle
on iOS which are important.

348
00:16:39.906 --> 00:16:42.146 A:middle
So your application
sometimes needs

349
00:16:42.146 --> 00:16:43.136 A:middle
to render in the background.

350
00:16:43.426 --> 00:16:46.006 A:middle
Often either when the app is
just transitioning to background

351
00:16:46.006 --> 00:16:48.266 A:middle
or when it's fully in
the background state.

352
00:16:48.666 --> 00:16:50.276 A:middle
On iOS 7, that is supported.

353
00:16:50.626 --> 00:16:53.946 A:middle
However all background renders
used the slower Core Image CPU

354
00:16:53.946 --> 00:16:54.566 A:middle
Rendering path.

355
00:16:55.606 --> 00:16:58.196 A:middle
On iOS 8, we have an improvement
in this regard which is

356
00:16:58.196 --> 00:17:00.106 A:middle
that renders that occur
within a short time

357
00:17:00.106 --> 00:17:03.836 A:middle
of switching the background will
now use the faster GPU renderer.

358
00:17:04.846 --> 00:17:07.996 A:middle
Now, it is serviced with a lower
GPU priority and the advantage

359
00:17:07.996 --> 00:17:10.306 A:middle
to that is that any
foreground renderers that happen

360
00:17:10.306 --> 00:17:11.736 A:middle
at that time will not be --

361
00:17:11.876 --> 00:17:13.266 A:middle
have any performance impact

362
00:17:13.685 --> 00:17:16.636 A:middle
because Core Image will be
using a lower priority renderer.

363
00:17:17.306 --> 00:17:18.636 A:middle
So this is another
great advantage.

364
00:17:19.806 --> 00:17:23.066 A:middle
There are some restrictions
on this GPU usage.

365
00:17:23.326 --> 00:17:27.076 A:middle
It is not allowed if you use
CIContext drawImage inRect

366
00:17:27.076 --> 00:17:29.956 A:middle
fromRect because in that case,
Core Image needs to render

367
00:17:29.956 --> 00:17:32.476 A:middle
into the client's
[inaudible] context.

368
00:17:32.826 --> 00:17:36.316 A:middle
However, any of the other render
methods calling createCGImage

369
00:17:36.316 --> 00:17:37.916 A:middle
or render toCVPixelBuffer

370
00:17:38.166 --> 00:17:43.506 A:middle
or render toBitmap will
all work in this way.

371
00:17:44.116 --> 00:17:47.676 A:middle
Another great improvement we
have is oftentimes you want

372
00:17:47.826 --> 00:17:50.246 A:middle
to do rendering in the
foreground when your app is

373
00:17:50.246 --> 00:17:52.146 A:middle
in the foreground but do it

374
00:17:52.196 --> 00:17:54.766 A:middle
from a secondary thread
in a polite manner.

375
00:17:55.246 --> 00:17:58.336 A:middle
So if your application
is showing one thing

376
00:17:58.336 --> 00:17:59.146 A:middle
and then doing something

377
00:17:59.146 --> 00:18:02.906 A:middle
on a secondary thread
using Core Image, on iOS 7,

378
00:18:02.906 --> 00:18:05.826 A:middle
that required care
in order to avoid --

379
00:18:06.116 --> 00:18:10.386 A:middle
in order for the secondary
thread to avoid causing glitches

380
00:18:10.386 --> 00:18:11.266 A:middle
for the foreground thread.

381
00:18:12.106 --> 00:18:14.486 A:middle
And of course, the only
sure-fire way to avoid that was

382
00:18:14.486 --> 00:18:16.866 A:middle
to use Core Image's
slower CPU renderer.

383
00:18:17.486 --> 00:18:19.926 A:middle
On iOS 8, we have a new feature

384
00:18:20.226 --> 00:18:24.246 A:middle
which is the secondary thread
can now render into a context

385
00:18:24.246 --> 00:18:26.396 A:middle
that has had this
new option specified

386
00:18:26.436 --> 00:18:29.396 A:middle
which is CIContext
PriorityRequestLow.

387
00:18:30.256 --> 00:18:33.436 A:middle
And the idea now is that
context renders using

388
00:18:33.546 --> 00:18:37.486 A:middle
that context will not
interrupt any foreground higher

389
00:18:37.486 --> 00:18:38.426 A:middle
priority renders.

390
00:18:38.786 --> 00:18:40.486 A:middle
So this is also great
for your application.

391
00:18:41.246 --> 00:18:43.956 A:middle
So this brings me to
some final thoughts

392
00:18:43.956 --> 00:18:46.226 A:middle
on Core Image's CPU rendering.

393
00:18:46.956 --> 00:18:50.156 A:middle
Basically, there were three key
reasons why an app would need

394
00:18:50.156 --> 00:18:52.866 A:middle
to use the CPU renderer
on iOS 7.

395
00:18:52.866 --> 00:18:56.006 A:middle
For example, the CPU
renderer was used

396
00:18:56.006 --> 00:18:59.856 A:middle
when GPU texture
limits were exceeded.

397
00:19:00.226 --> 00:19:04.066 A:middle
Well, starting on iOS 8, that's
no longer a limit in Core Image

398
00:19:04.066 --> 00:19:05.266 A:middle
so that's not a reason anymore.

399
00:19:06.086 --> 00:19:09.656 A:middle
Similarly, the application might
have needed to render briefly

400
00:19:09.656 --> 00:19:13.556 A:middle
when in the background, that's
also been improved in iOS 8.

401
00:19:14.756 --> 00:19:17.256 A:middle
And lastly, if your
application wanted to render

402
00:19:17.256 --> 00:19:19.516 A:middle
from a secondary thread
when in the foreground,

403
00:19:20.606 --> 00:19:22.606 A:middle
you might have used the
CPU renderer and now

404
00:19:22.606 --> 00:19:25.596 A:middle
that is no longer a limitation.

405
00:19:25.906 --> 00:19:28.476 A:middle
So we have some great
ways to keep us

406
00:19:28.476 --> 00:19:31.786 A:middle
on Core Image's much
faster GPU rendering path.

407
00:19:33.336 --> 00:19:36.396 A:middle
The next subject I want to
talk about this afternoon is

408
00:19:36.396 --> 00:19:38.326 A:middle
about some API modernizations

409
00:19:38.326 --> 00:19:41.286 A:middle
that have been made
both on OS X and on iOS.

410
00:19:41.856 --> 00:19:45.546 A:middle
These are small conveniences
but they add up in total.

411
00:19:45.816 --> 00:19:48.286 A:middle
First off, Core Image
filter subclasses

412
00:19:48.286 --> 00:19:51.156 A:middle
on OS X can now use
properties instead of ivars.

413
00:19:51.856 --> 00:19:54.026 A:middle
One thing to be aware of is

414
00:19:54.026 --> 00:19:57.976 A:middle
that Core Image filter
subclasses do not need

415
00:19:57.976 --> 00:20:02.956 A:middle
to release the object associated
with input ivars or properties.

416
00:20:03.156 --> 00:20:05.886 A:middle
So it's a little bit nonstandard
as a class in that regard.

417
00:20:07.136 --> 00:20:09.876 A:middle
By supporting properties,
that means that code that used

418
00:20:09.876 --> 00:20:12.656 A:middle
to look like this where you
have output image equals filter

419
00:20:12.986 --> 00:20:18.296 A:middle
valueForKey kCIOutputImageKey
can now be a little cleaner

420
00:20:18.296 --> 00:20:21.516 A:middle
and just look like outImage
equals filter.outputImage.

421
00:20:23.856 --> 00:20:26.986 A:middle
We also have a convenience
method if you want

422
00:20:26.986 --> 00:20:29.086 A:middle
to create a filter
and also set a bunch

423
00:20:29.086 --> 00:20:30.756 A:middle
of parameters all
in one fell swoop.

424
00:20:31.356 --> 00:20:34.086 A:middle
This can be now done by
saying filter, filterWithName

425
00:20:34.446 --> 00:20:37.936 A:middle
and then you could specify some
parameters at the same time.

426
00:20:38.576 --> 00:20:40.576 A:middle
And in those parameters
are a dictionary

427
00:20:40.576 --> 00:20:44.186 A:middle
where you can specify all the
inputs in one convenient manner.

428
00:20:45.876 --> 00:20:47.956 A:middle
There's an even slightly
simpler case

429
00:20:47.956 --> 00:20:50.736 A:middle
which is very commonly
usable where one

430
00:20:50.736 --> 00:20:53.006 A:middle
of your inputs is an input
image and you just want

431
00:20:53.006 --> 00:20:54.696 A:middle
to get the output of a filter.

432
00:20:55.056 --> 00:20:58.266 A:middle
So this means you can apply a
filter to an image with a set

433
00:20:58.266 --> 00:21:00.486 A:middle
of parameters without even
creating a filter object.

434
00:21:03.616 --> 00:21:05.546 A:middle
Lastly, one of the
common questions we get

435
00:21:05.546 --> 00:21:08.566 A:middle
from developers is, "How do
I correctly orient my image

436
00:21:08.566 --> 00:21:11.026 A:middle
so the orientation is
correctly upright?"

437
00:21:11.756 --> 00:21:15.286 A:middle
And the standard TIFF
specification has a set

438
00:21:15.286 --> 00:21:18.476 A:middle
of 8 possible values that tell
how the image should be flipped

439
00:21:18.476 --> 00:21:22.446 A:middle
or rotated and we've provided
a code snippet in the past

440
00:21:22.446 --> 00:21:25.626 A:middle
for that but much easier
is that we provided an API

441
00:21:25.626 --> 00:21:28.616 A:middle
for that now in iOS 8 and OS X.

442
00:21:28.976 --> 00:21:31.536 A:middle
So the simplest way
of calling it is

443
00:21:31.536 --> 00:21:34.266 A:middle
to say
imageByApplyingOrientation

444
00:21:34.766 --> 00:21:36.476 A:middle
and that gives you
back a new image.

445
00:21:36.906 --> 00:21:39.786 A:middle
And again, you're specifying
an integer orientation value.

446
00:21:40.326 --> 00:21:44.376 A:middle
As an alternative to doing the
same thing, we also have an API

447
00:21:44.376 --> 00:21:47.526 A:middle
that allows you to get
back the fine transform

448
00:21:47.526 --> 00:21:48.486 A:middle
that is equivalent to that.

449
00:21:49.296 --> 00:21:52.886 A:middle
And the reason why that's useful
is usually orienting your image

450
00:21:52.886 --> 00:21:57.066 A:middle
upright is only the
first of several affines

451
00:21:57.066 --> 00:21:58.486 A:middle
that you may apply
to your image.

452
00:21:58.486 --> 00:22:00.666 A:middle
You may also be scaling
it to fit or panning it.

453
00:22:01.236 --> 00:22:05.376 A:middle
And so by getting this affine
matrix and concatenating

454
00:22:05.376 --> 00:22:06.706 A:middle
with any other affine matrix,

455
00:22:06.706 --> 00:22:08.616 A:middle
you can get a little better
performance out of Core Image.

456
00:22:12.156 --> 00:22:15.366 A:middle
So we've also made some
modernizations on OS X

457
00:22:15.366 --> 00:22:16.646 A:middle
with regard to color spaces.

458
00:22:17.146 --> 00:22:20.876 A:middle
The default RGB color space
is now sRGB which is great

459
00:22:20.876 --> 00:22:24.176 A:middle
because it matches with
the default RGB color space

460
00:22:24.176 --> 00:22:25.096 A:middle
that we have on iOS.

461
00:22:25.296 --> 00:22:29.376 A:middle
It also matches what most
modern applications expect

462
00:22:29.376 --> 00:22:31.326 A:middle
for untagged images.

463
00:22:33.106 --> 00:22:37.676 A:middle
Similarly, our default working
space has also changed on OS X.

464
00:22:37.806 --> 00:22:43.176 A:middle
It is now a linearized version
of the Rec.709 chromaticities

465
00:22:43.566 --> 00:22:45.676 A:middle
and again, this matches
the default we have

466
00:22:45.676 --> 00:22:47.686 A:middle
for our working space on iOS

467
00:22:47.866 --> 00:22:50.526 A:middle
and has a great performance
advantage which means

468
00:22:50.526 --> 00:22:52.046 A:middle
that in most typical scenarios

469
00:22:52.046 --> 00:22:55.286 A:middle
where you have sRGB
content going into a filter

470
00:22:55.286 --> 00:22:58.226 A:middle
in its working space and then
going back to sRGB output,

471
00:22:58.546 --> 00:23:00.226 A:middle
no matrix math is needed at all

472
00:23:00.616 --> 00:23:02.256 A:middle
so this is a great,
great advantage.

473
00:23:02.496 --> 00:23:06.676 A:middle
Next subject, I'd like to talk

474
00:23:06.676 --> 00:23:10.506 A:middle
about today is some new
built-in Core Image filters.

475
00:23:11.836 --> 00:23:14.546 A:middle
So we have several I'd
like to talk about.

476
00:23:14.546 --> 00:23:18.756 A:middle
One is new to iOS 8 is
we've added CIAreaHistogram

477
00:23:18.756 --> 00:23:20.576 A:middle
and CIHistogramDisplayFilter.

478
00:23:21.196 --> 00:23:22.576 A:middle
The first filter,

479
00:23:22.576 --> 00:23:26.756 A:middle
CIAreaHistogram takes an
input image and the rectangle

480
00:23:26.756 --> 00:23:28.536 A:middle
that you want to generate
the histogram of it

481
00:23:28.966 --> 00:23:32.736 A:middle
and it'll produce an output
image that's typically 256

482
00:23:32.736 --> 00:23:33.856 A:middle
by 1 pixels.

483
00:23:34.386 --> 00:23:36.566 A:middle
So that image is useful
if you want to render

484
00:23:36.566 --> 00:23:37.826 A:middle
and get the pixel
values out of it

485
00:23:37.826 --> 00:23:41.296 A:middle
because that'll give you your
histogram data very efficiently.

486
00:23:42.196 --> 00:23:43.826 A:middle
However, oftentimes
you also want

487
00:23:43.826 --> 00:23:45.746 A:middle
to display this histogram
to the user.

488
00:23:46.146 --> 00:23:49.556 A:middle
So we have a second filter which
is CIHistogramDisplayFilter.

489
00:23:49.876 --> 00:23:53.286 A:middle
And it takes as an input
this 256 by 1 pixel image

490
00:23:53.696 --> 00:23:56.296 A:middle
and it produces a
pretty graph with red,

491
00:23:56.296 --> 00:23:57.856 A:middle
green and blue graphs
in it just like this.

492
00:23:58.956 --> 00:24:00.596 A:middle
It's very easy to use
in your application.

493
00:24:00.596 --> 00:24:02.066 A:middle
You just chain together
these two filters.

494
00:24:03.696 --> 00:24:06.676 A:middle
This is another great filter
that I'm really pleased with.

495
00:24:06.676 --> 00:24:10.166 A:middle
This is -- we've always had
filters for doing Gaussian blurs

496
00:24:10.166 --> 00:24:13.236 A:middle
on an image but we have a new
filter called MaskVariableBlur.

497
00:24:13.686 --> 00:24:16.016 A:middle
And the idea is you want
to apply a blur to an image

498
00:24:16.016 --> 00:24:17.976 A:middle
but you want to apply a
different amount of blur

499
00:24:17.976 --> 00:24:19.106 A:middle
at different locations.

500
00:24:19.276 --> 00:24:22.166 A:middle
So the way this filter works is
you start with an input image

501
00:24:22.716 --> 00:24:24.586 A:middle
and you provide a masked image.

502
00:24:24.896 --> 00:24:27.386 A:middle
In this example, we
have the mask is white

503
00:24:27.476 --> 00:24:31.846 A:middle
in the lower left-hand
corner, black in the center

504
00:24:32.086 --> 00:24:35.156 A:middle
and then white again the
upper right-hand corner.

505
00:24:35.656 --> 00:24:38.096 A:middle
And what this means when
we combine these two images

506
00:24:38.096 --> 00:24:41.146 A:middle
with masked variable blur
is we get a resulting image

507
00:24:41.506 --> 00:24:46.036 A:middle
that is defocused at the corners
and then gradually transitions

508
00:24:46.036 --> 00:24:47.596 A:middle
to a nice sharp image
in the center.

509
00:24:48.516 --> 00:24:51.216 A:middle
This is not just done with
blends but it's actually done

510
00:24:51.216 --> 00:24:53.716 A:middle
with variable radius blurs
which is quite a trick.

511
00:24:54.506 --> 00:24:56.726 A:middle
So there's a couple of
different ways you can use this.

512
00:24:56.726 --> 00:24:58.726 A:middle
You can use this to
achieve a sort of fake depth

513
00:24:58.726 --> 00:25:00.896 A:middle
of field effect where
the top and bottom

514
00:25:00.896 --> 00:25:03.056 A:middle
of your image might be blurry
and the center may be sharp.

515
00:25:03.676 --> 00:25:07.836 A:middle
Or you can actually hand create
a masked image with a person

516
00:25:07.836 --> 00:25:10.396 A:middle
in the foreground and then
nicely blur the background

517
00:25:10.396 --> 00:25:11.416 A:middle
with a nice bokeh.

518
00:25:12.926 --> 00:25:15.466 A:middle
So I hope to see lots
of fun examples of that.

519
00:25:16.416 --> 00:25:19.926 A:middle
This is another fun one we added
which is AccordionfoldTransition

520
00:25:19.926 --> 00:25:22.346 A:middle
and this is something
we did for the mail team

521
00:25:22.346 --> 00:25:24.486 A:middle
but we've also provided
it as a public filter.

522
00:25:24.846 --> 00:25:27.896 A:middle
You provide two images, a
before and an after and a couple

523
00:25:27.896 --> 00:25:30.316 A:middle
of parameters like how many
folds and how many pixels

524
00:25:30.316 --> 00:25:31.616 A:middle
at the bottom are shared.

525
00:25:32.296 --> 00:25:34.996 A:middle
And what this filter looks
like in practice is this.

526
00:25:35.896 --> 00:25:37.596 A:middle
And if you actually
look carefully,

527
00:25:37.866 --> 00:25:39.986 A:middle
that's the actual entire
kernel for this filter.

528
00:25:41.596 --> 00:25:46.606 A:middle
So it's a nice bit of trickery.

529
00:25:47.236 --> 00:25:50.666 A:middle
Another filter we've
added, in prior releases,

530
00:25:50.666 --> 00:25:53.256 A:middle
we've had filters for
generating QR codes.

531
00:25:53.916 --> 00:25:58.076 A:middle
We've added a new one for
generating code 128 barcodes

532
00:25:58.396 --> 00:25:59.936 A:middle
and it works in a
similar fashion.

533
00:25:59.936 --> 00:26:03.846 A:middle
You specify an input message
as NSData and in this case,

534
00:26:03.846 --> 00:26:06.256 A:middle
there's an additional parameter
which says how many pixels

535
00:26:06.256 --> 00:26:07.316 A:middle
of quiet space you want

536
00:26:08.326 --> 00:26:10.276 A:middle
and it'll produce
an image like this.

537
00:26:10.796 --> 00:26:13.226 A:middle
We've also added another
one for Aztec codes.

538
00:26:13.626 --> 00:26:15.546 A:middle
Again the same kind
of idea for the API,

539
00:26:15.666 --> 00:26:17.666 A:middle
you just specify
the input message

540
00:26:18.056 --> 00:26:19.806 A:middle
and for this particular
generator,

541
00:26:19.806 --> 00:26:21.606 A:middle
it has an input correction level

542
00:26:21.606 --> 00:26:26.876 A:middle
which tells how many error
correction bits it will have.

543
00:26:26.916 --> 00:26:31.596 A:middle
Another new filter which is also
fun is CIPerspectiveCorrection.

544
00:26:32.066 --> 00:26:34.176 A:middle
And the idea behind this
is you have an input image

545
00:26:34.176 --> 00:26:38.156 A:middle
and you specify 4 points and
it will create a new image

546
00:26:38.216 --> 00:26:41.606 A:middle
that is cropped and undistorted
preserving the original

547
00:26:41.636 --> 00:26:45.126 A:middle
and intended aspect ratio
so this is again very nice

548
00:26:45.126 --> 00:26:52.166 A:middle
for capturing parts of an
image and distorting them.

549
00:26:52.646 --> 00:26:55.726 A:middle
We've added a handful of
new blend filters, linear,

550
00:26:55.726 --> 00:26:58.136 A:middle
dodge and burn, pin
lights, subtract, divide.

551
00:26:58.826 --> 00:27:03.206 A:middle
Also just to be aware, we've
made a fix to SoftLightBlendMode

552
00:27:03.206 --> 00:27:06.606 A:middle
so it better matches the spec.

553
00:27:06.606 --> 00:27:09.456 A:middle
And then there's a few other new
ones we've added that are new

554
00:27:09.456 --> 00:27:12.276 A:middle
on iOS such as GlassDistortion,

555
00:27:12.276 --> 00:27:14.736 A:middle
StretchCrop for anamorphic
correction,

556
00:27:15.066 --> 00:27:16.846 A:middle
Droste which is a great demo

557
00:27:16.846 --> 00:27:20.966 A:middle
from our conference show two
years ago, and then who knows,

558
00:27:20.966 --> 00:27:22.756 A:middle
if we have some more time,
we'll get a few more in.

559
00:27:23.136 --> 00:27:26.676 A:middle
But what that brings us to today
is over 115 built-in filters

560
00:27:26.676 --> 00:27:29.666 A:middle
on iOS and of course, that
really is an infinite number now

561
00:27:29.666 --> 00:27:31.986 A:middle
that you guys can create
your own custom filters.

562
00:27:32.386 --> 00:27:34.516 A:middle
So we're excited to see
all sorts of new things.

563
00:27:35.916 --> 00:27:37.516 A:middle
Another area we've
made some improvements

564
00:27:37.516 --> 00:27:39.966 A:middle
in Core Image is CIDetectors.

565
00:27:40.186 --> 00:27:41.926 A:middle
So what is a CIDetector?

566
00:27:41.926 --> 00:27:44.666 A:middle
Well, CIDetector is an
abstract class that allows you

567
00:27:44.666 --> 00:27:46.276 A:middle
to help find things
within an image.

568
00:27:47.106 --> 00:27:51.606 A:middle
And prior to iOS 8, we had just
one type which was TypeFace.

569
00:27:52.186 --> 00:27:53.216 A:middle
But we've added two more.

570
00:27:53.306 --> 00:27:55.796 A:middle
So we now have
CIDetectorTypeRectangle

571
00:27:55.846 --> 00:27:57.886 A:middle
and CIDetectorTypeQRCode.

572
00:27:59.126 --> 00:28:00.986 A:middle
So how does this work?

573
00:28:00.986 --> 00:28:03.686 A:middle
Well, creating a detector is
largely the same regardless

574
00:28:03.686 --> 00:28:05.206 A:middle
of what type of detector
you are creating.

575
00:28:05.596 --> 00:28:08.566 A:middle
Here we have an example of
creating a detector of TypeFace

576
00:28:08.696 --> 00:28:10.736 A:middle
where we say detector,
detector of TypeFace

577
00:28:10.736 --> 00:28:12.536 A:middle
and we can also specify
some options.

578
00:28:13.146 --> 00:28:14.926 A:middle
There are a couple of
options that are very useful

579
00:28:14.926 --> 00:28:16.076 A:middle
for all the detectors.

580
00:28:16.076 --> 00:28:19.856 A:middle
One is you could say whether
you want to have high accuracy

581
00:28:19.856 --> 00:28:23.126 A:middle
or low accuracy which depending
on your need might allow you

582
00:28:23.126 --> 00:28:25.416 A:middle
to trade off performance
versus precision.

583
00:28:26.606 --> 00:28:29.646 A:middle
Also, you can tell a detector
what the smallest feature

584
00:28:29.646 --> 00:28:33.296 A:middle
to detect is and that also can
greatly improve performance.

585
00:28:33.826 --> 00:28:37.996 A:middle
And of course, now that we've
added these new detectors,

586
00:28:38.286 --> 00:28:40.066 A:middle
you can just use
DetectorTypeRectangle

587
00:28:40.776 --> 00:28:42.286 A:middle
or DetectorTypeQRCode as well.

588
00:28:44.256 --> 00:28:48.036 A:middle
So just as a reminder, so when
you're using the FaceDetector,

589
00:28:48.686 --> 00:28:51.116 A:middle
there's a couple of options
that you want to pass

590
00:28:51.116 --> 00:28:53.346 A:middle
in when you're asking for the
actual features in an image.

591
00:28:53.766 --> 00:28:56.476 A:middle
One is you can specify what the
orientation of the image is.

592
00:28:56.716 --> 00:28:58.986 A:middle
That's important because
the FaceDetector looks

593
00:28:58.986 --> 00:28:59.946 A:middle
for upright faces.

594
00:29:00.746 --> 00:29:02.736 A:middle
Also you can specify
options to say I want to look

595
00:29:02.736 --> 00:29:06.456 A:middle
for eye blinks or smiles
and that's specified

596
00:29:06.456 --> 00:29:07.566 A:middle
in the same options dictionary.

597
00:29:07.566 --> 00:29:10.946 A:middle
And let me show you
a little bit of code

598
00:29:10.946 --> 00:29:14.016 A:middle
about how we can now use this
detector to create a sort

599
00:29:14.016 --> 00:29:16.276 A:middle
of augmented reality
example here.

600
00:29:16.636 --> 00:29:18.396 A:middle
And the idea we wanted
for this little bit

601
00:29:18.396 --> 00:29:20.806 A:middle
of a sample code is we wanted
to start with the input image,

602
00:29:20.806 --> 00:29:24.246 A:middle
find the faces in it
and then put squares

603
00:29:24.246 --> 00:29:25.996 A:middle
over the image where
we find them.

604
00:29:25.996 --> 00:29:28.646 A:middle
And so this is a little
clever bit of sample code.

605
00:29:28.646 --> 00:29:32.536 A:middle
First off, for each face that
we detect in the features array,

606
00:29:33.266 --> 00:29:35.626 A:middle
we're going to check to see if
the eyes were closed or not.

607
00:29:36.346 --> 00:29:38.486 A:middle
Then we're going to
create a CIImage WithColor.

608
00:29:39.216 --> 00:29:41.746 A:middle
And we're going to have
a different color based

609
00:29:41.746 --> 00:29:43.546 A:middle
on whether the eyes
are closed or not

610
00:29:43.546 --> 00:29:45.536 A:middle
or whether face is
smiling or not.

611
00:29:46.096 --> 00:29:48.796 A:middle
Now that API actually
returns an infinite image

612
00:29:49.766 --> 00:29:53.156 A:middle
so what we then need to do is
to crop that image to the bounds

613
00:29:53.156 --> 00:29:54.366 A:middle
of the feature that
was detected.

614
00:29:55.406 --> 00:29:59.826 A:middle
We then take that cropped
image color and we composite

615
00:29:59.826 --> 00:30:01.676 A:middle
over the previous
resulting image.

616
00:30:02.156 --> 00:30:04.106 A:middle
And this is also a new
API that we've provided.

617
00:30:04.106 --> 00:30:07.456 A:middle
It's basically convenience
API that's equivalent

618
00:30:07.456 --> 00:30:10.296 A:middle
to using the Core Image source
over compositing filter.

619
00:30:10.776 --> 00:30:12.866 A:middle
And this is what it
looks like in practice.

620
00:30:12.866 --> 00:30:14.326 A:middle
Here's a little sample
video we shot

621
00:30:14.326 --> 00:30:18.516 A:middle
where we are detecting
the faces in real time

622
00:30:18.516 --> 00:30:22.316 A:middle
and then coloring them based
on whether the face is smiling

623
00:30:22.316 --> 00:30:23.696 A:middle
or blinking or combinations.

624
00:30:24.116 --> 00:30:26.626 A:middle
And we're getting about
25 frames per second.

625
00:30:27.136 --> 00:30:32.096 A:middle
We could do something similar
also for rectangle features.

626
00:30:32.096 --> 00:30:36.426 A:middle
So the idea behind rectangle
features is we understand

627
00:30:36.426 --> 00:30:40.446 A:middle
that in a lot of cases,
the first step in looking

628
00:30:40.486 --> 00:30:43.116 A:middle
in an image for something
interesting is to look

629
00:30:43.116 --> 00:30:44.256 A:middle
for something like a rectangle.

630
00:30:44.386 --> 00:30:47.006 A:middle
For example, if you're looking
for a sign or if you're looking

631
00:30:47.006 --> 00:30:49.886 A:middle
for a business card or if you're
looking for a piece of paper,

632
00:30:50.116 --> 00:30:52.846 A:middle
oftentimes looking for the
rectangle first is a great place

633
00:30:52.846 --> 00:30:53.246 A:middle
to start.

634
00:30:53.576 --> 00:30:56.676 A:middle
So we've created a generic
rectangle detector object

635
00:30:57.236 --> 00:31:00.176 A:middle
and it takes one
option parameter

636
00:31:00.176 --> 00:31:02.356 A:middle
which is the aspect ratio
that we want to search for.

637
00:31:03.086 --> 00:31:05.496 A:middle
And again, you can
ask the detector

638
00:31:05.496 --> 00:31:07.236 A:middle
to return the features array.

639
00:31:07.796 --> 00:31:09.706 A:middle
Now right now, it just
returns one rectangle

640
00:31:09.706 --> 00:31:11.056 A:middle
but that may change
in the future.

641
00:31:12.066 --> 00:31:14.476 A:middle
So here again, we wanted
to do a little sample here,

642
00:31:14.476 --> 00:31:16.666 A:middle
a little bit fancier
because we want to,

643
00:31:16.666 --> 00:31:19.336 A:middle
instead of just doing
the bounding box overlay,

644
00:31:19.646 --> 00:31:21.316 A:middle
we want to make it a
little bit prettier.

645
00:31:21.746 --> 00:31:24.546 A:middle
So again, we're looping over
all the features in the image.

646
00:31:25.366 --> 00:31:29.736 A:middle
We're creating a CIImage
WithColor which is infinite.

647
00:31:30.626 --> 00:31:33.846 A:middle
But we're going to take that
infinite color image and run it

648
00:31:33.846 --> 00:31:36.286 A:middle
through the
CIPerspectiveTransform

649
00:31:36.416 --> 00:31:37.796 A:middle
WithExtent filter.

650
00:31:38.366 --> 00:31:40.456 A:middle
And that filter does two things.

651
00:31:40.456 --> 00:31:42.196 A:middle
First of all, you
specify an extent

652
00:31:42.576 --> 00:31:45.586 A:middle
which in this case
we're specifying 0011

653
00:31:45.936 --> 00:31:48.396 A:middle
so now effectively, we
have a unit square image.

654
00:31:49.246 --> 00:31:51.816 A:middle
And then the other parameters,
take that unit square

655
00:31:51.816 --> 00:31:56.456 A:middle
and stretch it to the top-left,
top-right, bottom-left,

656
00:31:56.526 --> 00:31:57.656 A:middle
bottom-right coordinates.

657
00:31:58.226 --> 00:32:00.156 A:middle
And then we overlay that
on the previous result.

658
00:32:00.866 --> 00:32:02.556 A:middle
And here's what that
looks like in practice.

659
00:32:02.596 --> 00:32:06.176 A:middle
So this is the nameplate from
my office and we are taking,

660
00:32:06.326 --> 00:32:10.326 A:middle
running it through the Detector,
getting the detected rectangle

661
00:32:10.326 --> 00:32:12.676 A:middle
and then producing this
overlay tinted red image.

662
00:32:15.496 --> 00:32:18.676 A:middle
Lastly, we can do the
same thing with QR Codes.

663
00:32:19.036 --> 00:32:20.776 A:middle
The code here is
exactly the same.

664
00:32:21.196 --> 00:32:22.046 A:middle
The only difference is

665
00:32:22.046 --> 00:32:24.826 A:middle
that we're using the QR
Code feature instead.

666
00:32:25.486 --> 00:32:28.066 A:middle
This example, you could
have also gotten the message

667
00:32:28.066 --> 00:32:29.666 A:middle
from the QR Code
but in this case,

668
00:32:29.666 --> 00:32:31.336 A:middle
I'm just going to do an overlay.

669
00:32:32.016 --> 00:32:35.426 A:middle
So all I needed to do was
use the coordinates and again

670
00:32:35.426 --> 00:32:38.736 A:middle
as you see in the example,
we can detect this QR Code

671
00:32:38.736 --> 00:32:43.896 A:middle
and do an overlay in real time.

672
00:32:44.116 --> 00:32:46.946 A:middle
So that's the bulk of
my conversation there.

673
00:32:46.946 --> 00:32:49.936 A:middle
The last thing I want to
talk about is improvements

674
00:32:49.936 --> 00:32:53.086 A:middle
that we've made to
RAW support on OS X.

675
00:32:53.086 --> 00:32:55.766 A:middle
So let me talk a little
bit about our RAW support.

676
00:32:57.176 --> 00:33:00.066 A:middle
So I'll talk about our
history, the fundamentals

677
00:33:00.066 --> 00:33:03.616 A:middle
of RAW image processing,
some architectural overview

678
00:33:03.876 --> 00:33:05.836 A:middle
and how you can use this
great filter we have called

679
00:33:05.836 --> 00:33:06.766 A:middle
the CIRAWFilter.

680
00:33:07.846 --> 00:33:11.436 A:middle
So history first, so Apple
has been supporting RAW

681
00:33:11.436 --> 00:33:14.926 A:middle
since back in April of 2005.

682
00:33:15.096 --> 00:33:17.446 A:middle
Over those years, we have been
continuously adding support

683
00:33:17.446 --> 00:33:19.066 A:middle
for cameras and improving
the quality.

684
00:33:19.556 --> 00:33:22.696 A:middle
We have about 350
cameras supported today

685
00:33:22.696 --> 00:33:26.606 A:middle
and that's not including
all the DNG possibilities.

686
00:33:26.826 --> 00:33:30.486 A:middle
And one of the improvements
we've made in OS X this year is

687
00:33:30.486 --> 00:33:33.256 A:middle
that we support the latest
version of DNG specification

688
00:33:33.586 --> 00:33:34.966 A:middle
so that greatly improves
the number

689
00:33:34.966 --> 00:33:36.226 A:middle
of images that we can support.

690
00:33:36.706 --> 00:33:40.306 A:middle
And the other thing that's
wonderful about our support is

691
00:33:40.306 --> 00:33:42.476 A:middle
that it's provided to the
entire operating system

692
00:33:42.636 --> 00:33:45.126 A:middle
which means everything
from NSImages

693
00:33:45.126 --> 00:33:47.776 A:middle
to CGImages will
automatically support RAW files.

694
00:33:48.486 --> 00:33:52.316 A:middle
System services like Spotlight
and Quick Look support,

695
00:33:52.716 --> 00:33:56.456 A:middle
these key applications
like Preview, Finder,

696
00:33:56.456 --> 00:33:57.796 A:middle
even Mail support RAW.

697
00:33:58.456 --> 00:34:02.066 A:middle
Our photo applications
Aperture, iPhoto and Photos.

698
00:34:03.346 --> 00:34:06.176 A:middle
Also all third-party
app can also get this

699
00:34:06.176 --> 00:34:07.766 A:middle
for very little effort.

700
00:34:10.096 --> 00:34:12.446 A:middle
So what is involved in
processing a RAW image?

701
00:34:12.446 --> 00:34:16.596 A:middle
And this is why, you know, this
subject is actually very dear

702
00:34:16.596 --> 00:34:18.556 A:middle
to my heart because
it involves a lot

703
00:34:18.556 --> 00:34:19.946 A:middle
of very advanced
image processing

704
00:34:19.946 --> 00:34:20.976 A:middle
to produce a RAW file.

705
00:34:21.755 --> 00:34:22.936 A:middle
So you start off with the fact

706
00:34:22.936 --> 00:34:26.156 A:middle
that RAW files contain only
a minimally processed data

707
00:34:26.266 --> 00:34:27.786 A:middle
from the camera sensor image.

708
00:34:28.065 --> 00:34:32.676 A:middle
And in fact, the image is
actually missing typically 66%

709
00:34:32.676 --> 00:34:35.326 A:middle
of the actual data because
at each pixel location,

710
00:34:35.326 --> 00:34:37.406 A:middle
you only have a red or
a green or a blue value.

711
00:34:38.045 --> 00:34:40.966 A:middle
And that means to produce a
final image, we actually have

712
00:34:41.466 --> 00:34:45.696 A:middle
to make up good values for
those missing 60% of your data.

713
00:34:46.396 --> 00:34:49.235 A:middle
And that requires a lot of
advanced image processing

714
00:34:49.235 --> 00:34:52.266 A:middle
to produce a beautiful
image at the end.

715
00:34:52.545 --> 00:34:54.226 A:middle
There are several
steps in this process.

716
00:34:54.676 --> 00:34:57.196 A:middle
They involve extracting
critical metadata from the file,

717
00:34:57.316 --> 00:35:00.376 A:middle
decoding the raw sensor,
de-mosaic deconstruction

718
00:35:00.376 --> 00:35:02.456 A:middle
which is a hugely complex task,

719
00:35:02.936 --> 00:35:04.996 A:middle
lens correction,
noise reduction.

720
00:35:05.366 --> 00:35:06.966 A:middle
And then there's a set
of operations that are

721
00:35:06.966 --> 00:35:10.626 A:middle
in the color domain such as
mapping scene-referred color

722
00:35:10.626 --> 00:35:14.176 A:middle
values to output-referred
and then adjusting exposure

723
00:35:14.176 --> 00:35:17.506 A:middle
and temperature and tint
and then adding contrast

724
00:35:17.506 --> 00:35:19.036 A:middle
and saturation to taste.

725
00:35:19.436 --> 00:35:22.236 A:middle
So it's a lot of steps and
we've made some significant

726
00:35:22.236 --> 00:35:26.736 A:middle
improvements to several
of these in OS X Yosemite.

727
00:35:27.076 --> 00:35:29.266 A:middle
So we've benefitted
for lens correction,

728
00:35:29.266 --> 00:35:31.506 A:middle
a great new noise reduction
which we'll show in a minute

729
00:35:32.006 --> 00:35:33.996 A:middle
and also some improvements
to color as well.

730
00:35:36.076 --> 00:35:39.926 A:middle
So as I said before,
APIs like NSImage

731
00:35:39.926 --> 00:35:42.486 A:middle
and CGImage will get
RAW support for free.

732
00:35:43.236 --> 00:35:47.236 A:middle
And that's because our support
provides that default rendering

733
00:35:47.786 --> 00:35:50.566 A:middle
which is processed according
to all of our parameters

734
00:35:50.796 --> 00:35:53.186 A:middle
and whatever our
latest algorithm is.

735
00:35:55.096 --> 00:35:59.186 A:middle
However, we have this API
which is called the CIRAWFilter

736
00:35:59.506 --> 00:36:01.666 A:middle
which gives your
application much more control.

737
00:36:01.666 --> 00:36:06.746 A:middle
And it allows you to get a
CIImage with extended range,

738
00:36:06.746 --> 00:36:10.146 A:middle
floating point precision
and also

739
00:36:10.146 --> 00:36:13.086 A:middle
on that object are
easy-to-use controls

740
00:36:13.086 --> 00:36:16.196 A:middle
to control how our RAW
imaging results are processed.

741
00:36:16.806 --> 00:36:18.866 A:middle
And it gives you fast
interactive performance all

742
00:36:18.866 --> 00:36:19.336 A:middle
in the GPU.

743
00:36:19.736 --> 00:36:22.056 A:middle
So it's some great stuff that
you can use in your application.

744
00:36:23.756 --> 00:36:26.456 A:middle
So this is sort of how it
works as a flow diagram.

745
00:36:26.736 --> 00:36:29.986 A:middle
You start out with a file
and that can be passed either

746
00:36:29.986 --> 00:36:32.196 A:middle
as a file URL or NSData.

747
00:36:32.616 --> 00:36:35.976 A:middle
And that's passed as an input
to create the CIRAWFilter.

748
00:36:37.066 --> 00:36:40.166 A:middle
Also it can be specified on
that RAW filter are several

749
00:36:40.166 --> 00:36:41.896 A:middle
of our processing parameters.

750
00:36:42.686 --> 00:36:46.526 A:middle
Once you've set those correctly,
you can get a CIImage output

751
00:36:47.056 --> 00:36:49.646 A:middle
which you can then
display on the screen.

752
00:36:49.946 --> 00:36:52.266 A:middle
And by default, it'll look just
like our default rendering.

753
00:36:53.316 --> 00:36:55.826 A:middle
However, the great thing
about the CIRAWFilter is

754
00:36:55.826 --> 00:36:57.276 A:middle
that once the user
has seen those

755
00:36:57.546 --> 00:36:59.316 A:middle
and if your application
has controls,

756
00:36:59.706 --> 00:37:05.096 A:middle
you can alter those values, send
them back into the CIRAWFilter

757
00:37:05.546 --> 00:37:09.376 A:middle
where it can be re-displayed
all in real time.

758
00:37:09.906 --> 00:37:13.996 A:middle
Another great feature we have on
this is we actually have a place

759
00:37:13.996 --> 00:37:16.896 A:middle
where you can insert a
custom CIFilter in the middle

760
00:37:16.896 --> 00:37:20.666 A:middle
of our RAW filter processing
before we've done anything

761
00:37:20.666 --> 00:37:23.126 A:middle
to change the data
from a linear space.

762
00:37:23.126 --> 00:37:24.776 A:middle
So this is very useful
if you want

763
00:37:24.776 --> 00:37:26.396 A:middle
to do certain types
of image processing.

764
00:37:26.396 --> 00:37:28.616 A:middle
Now of course, you
can also apply filters

765
00:37:28.616 --> 00:37:32.846 A:middle
after the CIRAWFilter but this
is a great set of functionality

766
00:37:32.846 --> 00:37:33.936 A:middle
for certain use cases.

767
00:37:35.276 --> 00:37:37.546 A:middle
And lastly, it doesn't
have to go to the display.

768
00:37:37.546 --> 00:37:40.706 A:middle
You can also take the CIImage,
create a CGImage from that

769
00:37:41.206 --> 00:37:44.136 A:middle
and produce a new CG, a
file on disk from that.

770
00:37:44.566 --> 00:37:47.476 A:middle
And this is an example

771
00:37:47.476 --> 00:37:49.566 A:middle
of how little code it
takes to use this filter.

772
00:37:50.256 --> 00:37:51.846 A:middle
Basically, we start
out with a URL.

773
00:37:52.176 --> 00:37:55.776 A:middle
We create a CIFilter
filterWithImageURL

774
00:37:55.776 --> 00:37:57.346 A:middle
and that'll return
to CIRAWFilter.

775
00:37:58.336 --> 00:38:00.266 A:middle
In this particular
example, we want to get

776
00:38:00.266 --> 00:38:02.286 A:middle
from that filter what
our default value

777
00:38:02.286 --> 00:38:03.986 A:middle
for the luminance
noise reduction was

778
00:38:04.286 --> 00:38:05.396 A:middle
that returns to us as an object.

779
00:38:06.046 --> 00:38:08.866 A:middle
We can then make slight changes
to that like say for example,

780
00:38:08.866 --> 00:38:11.876 A:middle
you want all of your images to
be slightly more noise-reduced.

781
00:38:12.126 --> 00:38:14.216 A:middle
You can take that
value, add a bit to it

782
00:38:14.396 --> 00:38:15.606 A:middle
and then set that
as a new value.

783
00:38:16.476 --> 00:38:18.016 A:middle
And then once you're
done setting values,

784
00:38:18.016 --> 00:38:19.086 A:middle
you can get an output image.

785
00:38:19.876 --> 00:38:21.266 A:middle
So with just a few
lines of code,

786
00:38:21.266 --> 00:38:24.166 A:middle
you can leverage all
of our RAW pipeline.

787
00:38:24.486 --> 00:38:27.576 A:middle
So to show this in
much more detail,

788
00:38:27.576 --> 00:38:29.086 A:middle
I'm going to pass the
stage over to Serhan

789
00:38:29.086 --> 00:38:30.526 A:middle
who will be giving
a live demo of this.

790
00:38:30.806 --> 00:38:31.096 A:middle
Thanks.

791
00:38:31.986 --> 00:38:34.456 A:middle
&gt;&gt; In this part of our talk,
I would like to show you some

792
00:38:34.456 --> 00:38:36.526 A:middle
of the great things
that you can also do

793
00:38:36.526 --> 00:38:39.666 A:middle
in your applications
using the CIRAWFilter

794
00:38:39.796 --> 00:38:43.136 A:middle
and OS X's built-in support
for RAW camera files.

795
00:38:44.056 --> 00:38:47.866 A:middle
To do that, we created a
very basic simple application

796
00:38:48.446 --> 00:38:52.556 A:middle
that simply puts
up an NSOpenGLView

797
00:38:52.556 --> 00:38:55.136 A:middle
which is tied up
to a CIRAWFilter.

798
00:38:55.776 --> 00:38:59.026 A:middle
And another NSView which is tied

799
00:38:59.026 --> 00:39:00.946 A:middle
up to the controls
of the CIRAWFilter.

800
00:39:01.436 --> 00:39:05.866 A:middle
So let me run that and
point it to a RAW image.

801
00:39:09.776 --> 00:39:13.226 A:middle
Now, by default, when you
actually open up a RAW file,

802
00:39:13.286 --> 00:39:15.766 A:middle
we will tap into our
own calibration database

803
00:39:15.866 --> 00:39:18.036 A:middle
and make sure that we
apply the correct set

804
00:39:18.036 --> 00:39:21.606 A:middle
of calibration settings that
are specific to the make

805
00:39:21.606 --> 00:39:23.086 A:middle
and model for this RAW file.

806
00:39:23.926 --> 00:39:28.026 A:middle
And some of the settings are
for you under lens correction,

807
00:39:28.626 --> 00:39:33.176 A:middle
white balance settings,
noise reduction settings

808
00:39:33.176 --> 00:39:36.016 A:middle
that we will go into more
detail in just a second,

809
00:39:36.556 --> 00:39:39.386 A:middle
exposure and boost controls.

810
00:39:40.726 --> 00:39:42.896 A:middle
So there is not much going

811
00:39:43.246 --> 00:39:45.366 A:middle
on with this very good
image in the first place.

812
00:39:45.366 --> 00:39:49.566 A:middle
So let me pull up a
more challenging image

813
00:39:49.566 --> 00:39:54.856 A:middle
to show the great benefits
of using RAW files.

814
00:39:55.396 --> 00:39:58.576 A:middle
Now, on this image, by
default when you load it,

815
00:39:58.576 --> 00:40:01.046 A:middle
you see that parts
of the image is close

816
00:40:01.046 --> 00:40:04.636 A:middle
to clipping point especially the
sky and the mountainous region.

817
00:40:05.046 --> 00:40:08.146 A:middle
So we're probably losing some
color fidelity in this region.

818
00:40:08.736 --> 00:40:13.016 A:middle
What's more interesting
is the part of the trees

819
00:40:13.016 --> 00:40:16.036 A:middle
which are underexposed and we're
probably not getting the right

820
00:40:16.036 --> 00:40:16.866 A:middle
amount of detail.

821
00:40:17.406 --> 00:40:19.706 A:middle
So let's see if we can
actually improve this image.

822
00:40:20.506 --> 00:40:22.456 A:middle
The first thing that I would

823
00:40:22.456 --> 00:40:24.776 A:middle
like to try is setting
the exposure

824
00:40:24.826 --> 00:40:26.326 A:middle
to see how it actually
looks like.

825
00:40:27.216 --> 00:40:30.776 A:middle
Want to probably increase
the exposure to make sure

826
00:40:30.776 --> 00:40:33.426 A:middle
that I get the detail in
the tree part of the image.

827
00:40:33.546 --> 00:40:34.976 A:middle
But as you can quickly see,

828
00:40:34.976 --> 00:40:36.926 A:middle
we're losing all the
detail in the highlights.

829
00:40:38.016 --> 00:40:39.836 A:middle
And the opposite is also true.

830
00:40:39.896 --> 00:40:41.766 A:middle
Once you start decreasing
the exposure,

831
00:40:42.236 --> 00:40:44.086 A:middle
you're getting back
the color in the sky

832
00:40:44.456 --> 00:40:47.376 A:middle
but you're losing all the
detail in the low lights.

833
00:40:48.776 --> 00:40:52.876 A:middle
So there is something that can
be done better and the answer

834
00:40:52.876 --> 00:40:55.406 A:middle
to that is CI Highlights
and Shadows Filters.

835
00:40:56.186 --> 00:40:59.276 A:middle
Normally, if you were shooting
JPEG, you would tie the output

836
00:40:59.276 --> 00:41:02.276 A:middle
of the JPEG decoder to this
highlights and shadows filters.

837
00:41:02.506 --> 00:41:05.446 A:middle
But what's interesting
when you're shooting RAW is

838
00:41:05.446 --> 00:41:08.996 A:middle
that you can actually insert
this filter into the middle

839
00:41:09.036 --> 00:41:12.066 A:middle
of our RAW processing
pipeline and take advantage

840
00:41:12.066 --> 00:41:14.876 A:middle
of the linear input space
that we're operating in.

841
00:41:15.416 --> 00:41:16.826 A:middle
That means that you will be able

842
00:41:16.826 --> 00:41:18.726 A:middle
to better keep the
color fidelity.

843
00:41:18.726 --> 00:41:21.396 A:middle
You'll operate on a
linear 16-bit pipeline

844
00:41:21.816 --> 00:41:23.596 A:middle
and at the end, get
better results.

845
00:41:23.826 --> 00:41:25.626 A:middle
So let's try that.

846
00:41:26.356 --> 00:41:29.766 A:middle
The first thing that I want
to do is increase the shadows

847
00:41:30.306 --> 00:41:33.086 A:middle
and almost immediately I
can see that all the detail

848
00:41:33.086 --> 00:41:36.776 A:middle
in the shadow part is
kept, is brought back.

849
00:41:37.326 --> 00:41:38.486 A:middle
Same for the sky.

850
00:41:38.486 --> 00:41:40.276 A:middle
I want to bring it
down to make sure

851
00:41:40.276 --> 00:41:42.516 A:middle
that I can see more
of the sky colors.

852
00:41:43.526 --> 00:41:47.266 A:middle
And I can easily do that
without overblowing any part

853
00:41:47.266 --> 00:41:47.996 A:middle
of that image.

854
00:41:49.656 --> 00:41:52.106 A:middle
So that is a good example

855
00:41:52.106 --> 00:41:55.216 A:middle
of how you can actually use
the CIRAWFilter to make sure

856
00:41:55.216 --> 00:41:58.516 A:middle
that you can double up your
own images in the best way

857
00:41:58.516 --> 00:42:00.186 A:middle
that you think is appropriate.

858
00:42:01.296 --> 00:42:07.236 A:middle
Next noise filter.

859
00:42:08.146 --> 00:42:11.526 A:middle
Now noise reduction is a
very challenging problem

860
00:42:11.526 --> 00:42:16.216 A:middle
and traditionally it
is very computationally

861
00:42:16.386 --> 00:42:18.336 A:middle
expensive algorithm.

862
00:42:18.986 --> 00:42:22.656 A:middle
We're very happy to offer you
a new noise reduction algorithm

863
00:42:22.656 --> 00:42:24.476 A:middle
starting in OS X Yosemite.

864
00:42:24.976 --> 00:42:28.206 A:middle
That doesn't compromise on the
quality and you can still use it

865
00:42:28.376 --> 00:42:30.696 A:middle
at an interactive 60
frames per second rate.

866
00:42:31.246 --> 00:42:34.296 A:middle
To show you that, we have
this very noisy image

867
00:42:35.456 --> 00:42:37.976 A:middle
of the Moscone Center
and I want to focus

868
00:42:37.976 --> 00:42:39.096 A:middle
on this part of the image.

869
00:42:40.016 --> 00:42:42.626 A:middle
Just for fun, I'm going to turn
off all the noise reduction

870
00:42:42.626 --> 00:42:44.556 A:middle
to see what we are
dealing with initially.

871
00:42:47.556 --> 00:42:49.186 A:middle
So this is the original --

872
00:42:49.236 --> 00:42:51.176 A:middle
this is how the original
image looks like.

873
00:42:51.966 --> 00:42:57.866 A:middle
And using the CIRAW LNR and
CNR noise filter settings,

874
00:42:57.866 --> 00:42:59.816 A:middle
I can get it to a
state where I feel

875
00:42:59.956 --> 00:43:02.336 A:middle
that is most comfortable
for my image.

876
00:43:02.926 --> 00:43:05.446 A:middle
So probably the first thing
that I want to do is get rid

877
00:43:05.446 --> 00:43:10.546 A:middle
of all the color noise and I'm
using the CNR slider to do that.

878
00:43:10.546 --> 00:43:12.726 A:middle
And look how interactive
this process is.

879
00:43:13.876 --> 00:43:17.016 A:middle
Same for LNR, you have a
wide variety of settings

880
00:43:17.016 --> 00:43:17.896 A:middle
that you can play with.

881
00:43:17.956 --> 00:43:21.266 A:middle
You can go with something that
is very smooth or something

882
00:43:21.266 --> 00:43:23.686 A:middle
which keeps all the
luminance noise.

883
00:43:24.076 --> 00:43:26.076 A:middle
So I want to probably hit
somewhere in the middle

884
00:43:26.076 --> 00:43:29.956 A:middle
where I got rid of most of
the noise but still kept some.

885
00:43:30.826 --> 00:43:34.006 A:middle
Another good thing that you
can do is brought back some

886
00:43:34.006 --> 00:43:36.746 A:middle
of the fine high
detail back to the image

887
00:43:36.746 --> 00:43:38.486 A:middle
after you clean up
all the bad noise.

888
00:43:38.576 --> 00:43:40.566 A:middle
So the detail slider is the one

889
00:43:40.566 --> 00:43:41.966 A:middle
that you would be
using for that.

890
00:43:42.756 --> 00:43:47.666 A:middle
And quickly you can get back to
this film grain type of look.

891
00:43:49.036 --> 00:43:52.456 A:middle
Same is true for high frequency
contrast and if you choose

892
00:43:52.456 --> 00:43:54.606 A:middle
to do that, you can also play

893
00:43:54.606 --> 00:43:57.166 A:middle
with it again 60
frames per second.

894
00:43:59.246 --> 00:44:01.006 A:middle
So that is the noise filter.

895
00:44:01.426 --> 00:44:04.056 A:middle
Starting with OS X
Yosemite, you'll also be able

896
00:44:04.056 --> 00:44:08.446 A:middle
to use this filter for your
JPEG images and this is going

897
00:44:08.446 --> 00:44:11.646 A:middle
to be a really nice advancement
on top of our offerings.

898
00:44:12.446 --> 00:44:14.586 A:middle
The last thing that I want

899
00:44:14.586 --> 00:44:16.486 A:middle
to show you today
is lens correction.

900
00:44:17.406 --> 00:44:19.716 A:middle
So a lot of the point-and-shoot
cameras

901
00:44:19.716 --> 00:44:22.476 A:middle
in the market today
are actually relying

902
00:44:22.476 --> 00:44:26.676 A:middle
on digital signal processing
techniques to fix some

903
00:44:26.676 --> 00:44:30.386 A:middle
of the compromises that
are made in the lenses.

904
00:44:31.286 --> 00:44:34.226 A:middle
What I mean by that, the
input image as you can see

905
00:44:34.296 --> 00:44:36.986 A:middle
by default is looking
correct to us.

906
00:44:37.426 --> 00:44:39.806 A:middle
But actual, the RAW
image that is coming

907
00:44:39.806 --> 00:44:41.516 A:middle
in is looking like this.

908
00:44:43.006 --> 00:44:46.146 A:middle
So whenever that data is
available in the file,

909
00:44:46.146 --> 00:44:47.956 A:middle
RAW camera will try
to do the right thing

910
00:44:47.956 --> 00:44:50.546 A:middle
and actually correct
for this aberration.

911
00:44:51.326 --> 00:44:54.896 A:middle
But for your own application,
you may choose to skip this step

912
00:44:54.896 --> 00:44:57.416 A:middle
and actually do your
own set of filters

913
00:44:57.416 --> 00:44:58.806 A:middle
or your own lens correction.

914
00:44:59.346 --> 00:45:03.786 A:middle
And it's an easy way
to actually go back

915
00:45:03.786 --> 00:45:08.016 A:middle
to the actual RAW sample
of the file itself.

916
00:45:09.736 --> 00:45:12.836 A:middle
I'm going to now quickly turn
it back to David who's going

917
00:45:12.836 --> 00:45:16.266 A:middle
to talk about usages
of the second GPU.

918
00:45:17.041 --> 00:45:19.041 A:middle
[ Applause ]

919
00:45:19.066 --> 00:45:20.516 A:middle
&gt;&gt; Thank you, Serhan.

920
00:45:20.516 --> 00:45:23.136 A:middle
So as you saw, we have this
great new noise reduction

921
00:45:23.136 --> 00:45:26.836 A:middle
and it's a very complex Core
Image filter that we developed

922
00:45:26.836 --> 00:45:32.086 A:middle
and it makes great use of
the GPU which brings us

923
00:45:32.086 --> 00:45:33.576 A:middle
up to talking about
the second GPU.

924
00:45:34.336 --> 00:45:37.956 A:middle
So a year ago, we announced
at the WWDC our new Mac Pro

925
00:45:37.956 --> 00:45:41.306 A:middle
which has this great feature
of having a second GPU,

926
00:45:41.856 --> 00:45:43.346 A:middle
just waiting for
your application

927
00:45:43.346 --> 00:45:44.266 A:middle
to take advantage of it.

928
00:45:44.916 --> 00:45:49.056 A:middle
So let's talk a little
of how that can be used.

929
00:45:49.936 --> 00:45:54.756 A:middle
So we had some thoughts about
for Core Image and for RAWs.

930
00:45:54.756 --> 00:45:57.926 A:middle
When is a good time where you
might want to use a second GPU?

931
00:45:58.536 --> 00:46:00.366 A:middle
And a couple of scenarios
come to mind.

932
00:46:00.706 --> 00:46:03.286 A:middle
One is if your application
has ability

933
00:46:03.286 --> 00:46:04.616 A:middle
to do speculative renders.

934
00:46:04.616 --> 00:46:07.346 A:middle
For example, you may have
a large list of images.

935
00:46:07.346 --> 00:46:10.676 A:middle
The user might be looking
at one but he may switch

936
00:46:10.676 --> 00:46:14.266 A:middle
to the previous or the
following image at any time.

937
00:46:14.846 --> 00:46:19.226 A:middle
Your application could be
speculatively rendering the next

938
00:46:19.226 --> 00:46:21.676 A:middle
or previous image
on a second thread.

939
00:46:22.566 --> 00:46:24.576 A:middle
Similarly, your application
may have the ability

940
00:46:24.576 --> 00:46:27.156 A:middle
to do a large batch
export and you want to do

941
00:46:27.156 --> 00:46:30.076 A:middle
that in the background and
you want to use the GPU

942
00:46:30.946 --> 00:46:33.716 A:middle
but you don't want
that background GPU

943
00:46:33.716 --> 00:46:35.746 A:middle
to affect your foreground
GPU usage.

944
00:46:36.016 --> 00:46:39.066 A:middle
So these are both great
reasons to use the second GPU

945
00:46:39.646 --> 00:46:42.836 A:middle
because it allows you to
get the best performance

946
00:46:42.956 --> 00:46:45.556 A:middle
without causing your
user interface

947
00:46:45.556 --> 00:46:47.506 A:middle
to stutter for its usage.

948
00:46:48.316 --> 00:46:50.426 A:middle
So how does one do that?

949
00:46:50.746 --> 00:46:53.236 A:middle
Well, you could do this
today on Mavericks.

950
00:46:53.416 --> 00:46:57.376 A:middle
It takes around 80 lines
of OpenGL code to tell,

951
00:46:57.726 --> 00:47:00.516 A:middle
to create a CIContext
that refers

952
00:47:00.516 --> 00:47:02.386 A:middle
to the second offline GPU.

953
00:47:03.446 --> 00:47:08.446 A:middle
However, we've added a simpler
API in Core Image on Yosemite

954
00:47:08.816 --> 00:47:11.976 A:middle
which is CIContext
offlineGPUAtIndex

955
00:47:11.976 --> 00:47:13.616 A:middle
and typically you
just specify zero.

956
00:47:13.986 --> 00:47:18.086 A:middle
So with one API call, you get
a CIContext and that when using

957
00:47:18.086 --> 00:47:20.476 A:middle
that all renders will
use the second GPU.

958
00:47:20.836 --> 00:47:22.106 A:middle
So it's very easy.

959
00:47:22.676 --> 00:47:25.216 A:middle
And to show that in action,
I'm going to bring Serhan back

960
00:47:25.216 --> 00:47:26.036 A:middle
up to do a quick demo.

961
00:47:27.876 --> 00:47:29.116 A:middle
&gt;&gt; Well, in our first demo,

962
00:47:29.176 --> 00:47:32.246 A:middle
we showed that even the most
computationally expensive noise

963
00:47:32.246 --> 00:47:35.086 A:middle
filter algorithm can be done
at 60 frames per second.

964
00:47:36.116 --> 00:47:38.986 A:middle
I'm going to bring that
application back and open

965
00:47:38.986 --> 00:47:40.296 A:middle
up a very noisy image.

966
00:47:49.046 --> 00:47:52.876 A:middle
So our LNR controls can be
done at 60 frames per second.

967
00:47:53.296 --> 00:47:57.176 A:middle
To show you that, we actually
wrote a little bit of code

968
00:47:57.346 --> 00:48:01.216 A:middle
to display the frames per second
when I'm actually sweeping

969
00:48:01.216 --> 00:48:02.936 A:middle
through all the noise
filter settings.

970
00:48:03.386 --> 00:48:07.606 A:middle
And as you can see, I'm
getting 60 frames per second all

971
00:48:07.606 --> 00:48:07.896 A:middle
the time.

972
00:48:08.356 --> 00:48:10.856 A:middle
Now let's say that you
have a background trait

973
00:48:11.186 --> 00:48:13.416 A:middle
where you are constantly
exporting images

974
00:48:13.486 --> 00:48:15.096 A:middle
and for some reason you wanted

975
00:48:15.096 --> 00:48:19.096 A:middle
to do a GPU pipe
on your first GPU.

976
00:48:19.856 --> 00:48:22.786 A:middle
To simulate that, we
have written a little bit

977
00:48:23.106 --> 00:48:27.326 A:middle
of text application which
is using the first GPU.

978
00:48:27.926 --> 00:48:30.486 A:middle
And when I go back
to my own application

979
00:48:30.546 --> 00:48:32.666 A:middle
which is now also
using my first GPU,

980
00:48:32.736 --> 00:48:38.246 A:middle
I can see that the frame rate is
actually suffering a little bit.

981
00:48:38.616 --> 00:48:41.396 A:middle
I'm going to run my test shoot
one more time to see what type

982
00:48:41.396 --> 00:48:42.976 A:middle
of frame rate I'm
getting out of this.

983
00:48:43.756 --> 00:48:47.856 A:middle
And you can quickly see that
it has dropped down to 50%.

984
00:48:47.856 --> 00:48:50.476 A:middle
I'm getting 24 frames
per second.

985
00:48:51.026 --> 00:48:55.516 A:middle
So can we do something
better than that?

986
00:48:55.516 --> 00:48:56.656 A:middle
And the answer is yes.

987
00:48:57.576 --> 00:49:00.026 A:middle
If we can offload this work

988
00:49:00.026 --> 00:49:05.366 A:middle
to our second GPU using
the CIGLOfflineContext,

989
00:49:05.536 --> 00:49:11.176 A:middle
I will get back to my original
performance in my active app.

990
00:49:11.476 --> 00:49:14.216 A:middle
And to show you that,
here we go one more time.

991
00:49:15.056 --> 00:49:18.686 A:middle
I can see that the user controls
are once again very smooth

992
00:49:18.986 --> 00:49:22.896 A:middle
and the frame rate that I'm
going to get is close to 60.

993
00:49:28.896 --> 00:49:31.806 A:middle
So once again, this is a
great way to take advantage

994
00:49:31.806 --> 00:49:35.946 A:middle
of the second GPU if you are
constantly doing computationally

995
00:49:35.946 --> 00:49:37.516 A:middle
heavy algorithms
in the background.

996
00:49:38.506 --> 00:49:40.816 A:middle
I'm going to hand it
back once over to David.

997
00:49:42.036 --> 00:49:43.666 A:middle
&gt;&gt; So to summarize what
we've talked about today.

998
00:49:43.666 --> 00:49:45.966 A:middle
We've talked about
some key concepts

999
00:49:45.966 --> 00:49:47.276 A:middle
to understand about Core Image.

1000
00:49:47.856 --> 00:49:50.426 A:middle
We've talked about what's
new in Core Image on iOS 8,

1001
00:49:50.836 --> 00:49:53.856 A:middle
most notably Custom CIKernels
and large image support.

1002
00:49:54.856 --> 00:49:57.206 A:middle
We talked about some
new things in Core Image

1003
00:49:57.386 --> 00:50:01.896 A:middle
on Yosemite notably
some API modernization

